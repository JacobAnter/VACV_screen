{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe purpose of this Jupyter notebook is to split the data set combining\\nboth positive and negative PPI instances into 10 equally sized chunks so\\nas to prepare k-fold cross-validation with k being equal to 10 here.\\n\\n10 is chosen as value for k since the test set is supposed to encompass\\n10% of the whole data.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The purpose of this Jupyter notebook is to split the data set combining\n",
    "both positive and negative PPI instances into 10 equally sized chunks so\n",
    "as to prepare k-fold cross-validation with k being equal to 10 here.\n",
    "\n",
    "10 is chosen as value for k since the test set is supposed to encompass\n",
    "10% of the whole data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from biotite.sequence.io import fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set combining both positive and negative instances into\n",
    "# a Pandas DataFrame\n",
    "pos_and_neg_VACV_WR_PPIs_df = pd.read_csv(\n",
    "    \"VACV_WR_pos_and_nucleolus_prots_neg_PPI_instances.tsv\",\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, perform the k-fold split\n",
    "# Note that the `split()` method of the `KFold` class merely provides\n",
    "# the indices of the data points belonging to the respective fold, not\n",
    "# the data points themselves\n",
    "# Thus, indexing of the DataFrame has to be performed in order to obtain\n",
    "# the actual data\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for i, (train_indices, test_indices) in enumerate(\n",
    "    kf.split(pos_and_neg_VACV_WR_PPIs_df)\n",
    "):\n",
    "    pos_and_neg_VACV_WR_PPIs_df.iloc[train_indices].to_csv(\n",
    "        f\"data_set_splits/VACV_WR_pos_and_neg_PPIs_train_val_split_{i}.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False\n",
    "    )\n",
    "    pos_and_neg_VACV_WR_PPIs_df.iloc[test_indices].to_csv(\n",
    "        f\"data_set_splits/VACV_WR_pos_and_neg_PPIs_test_split_{i}.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, SENSE-PPI entails the major drawback of reading in the\n",
    "# embeddings of all protein sequences listed in the given FASTA file at\n",
    "# once, thereby potentially causing an OutOfMemory (OOM) error\n",
    "# In an attempt to obviate such an OOM error, the test data set of each\n",
    "# and every split is subdivided into three chunks\n",
    "# For each chunk, a separate FASTA file is generated encompassing\n",
    "# exclusively the sequences of the proteins for that chunk\n",
    "N_CHUNKS = 3\n",
    "\n",
    "for i in range(10):\n",
    "    # Load the test data set of the current split into a Pandas\n",
    "    # DataFrame\n",
    "    current_test_set = pd.read_csv(\n",
    "        f\"data_set_splits/VACV_WR_pos_and_neg_PPIs_test_split_{i}.tsv\",\n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "\n",
    "    n_PPIs = len(current_test_set)\n",
    "    chunk_size = math.floor(n_PPIs / N_CHUNKS)\n",
    "    \n",
    "    for j in range(3):\n",
    "        if j < 2:\n",
    "            current_chunk = current_test_set.iloc[\n",
    "                j * chunk_size : (j + 1) * chunk_size\n",
    "            ]\n",
    "        else:\n",
    "            current_chunk = current_test_set.iloc[j * chunk_size :]\n",
    "        \n",
    "        # Save the current chunk to a TSV file\n",
    "        current_chunk.to_csv(\n",
    "            (\n",
    "                f\"data_set_splits/data_set_split_{i}/VACV_WR_pos_and_\"\n",
    "                f\"neg_PPIs_test_set_split_{i}_chunk_{j}.tsv\"\n",
    "            ),\n",
    "            sep=\"\\t\",\n",
    "            index=False,\n",
    "            header=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the subdivision into three chunks has been accomplished for\n",
    "# the test set of each and every split, the corresponding FASTA files\n",
    "# are created\n",
    "\n",
    "# Load the FASTA file encompassing all VACV WR and human protein\n",
    "# sequences\n",
    "all_VACV_WR_and_human_prots_fasta = fasta.FastaFile.read(\n",
    "    \"human_nucleolus_and_VACV_WR_prot_seqs.fasta\"\n",
    ")\n",
    "\n",
    "# Iterate over the splits, i.e. the individual test sets\n",
    "for i in range(10):\n",
    "    # Iterate over the chunks of an individual test set\n",
    "    for j in range(3):\n",
    "        # Load the TSV file of the current split and current chunk\n",
    "        current_split_and_chunk_PPIs_df = pd.read_csv(\n",
    "            f\"data_set_splits/data_set_split_{i}/VACV_WR_pos_and_\"\\\n",
    "                f\"neg_PPIs_test_set_split_{i}_chunk_{j}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            # As the individual chunks have been saved without header,\n",
    "            # it is important to also load them without header\n",
    "            # Otherwise, the first line will be interpreted as header\n",
    "            # Using this option, the columns are labelled with intergers\n",
    "            # in ascending order, i.e. in this case, the labels are 0, 1\n",
    "            # and 2\n",
    "            header=None\n",
    "        )\n",
    "\n",
    "        # Extract the unique UniProt IDs of both the human and the VACV\n",
    "        # WR proteins\n",
    "        # In order to determine the unique UniProt IDs of both human and\n",
    "        # VACV WR proteins at once, `pandas.unique()` is employed in\n",
    "        # conjunction with `pandas.melt()`, which transforms a DataFrame\n",
    "        # from a wide format into a long format\n",
    "        # This yields a DataFrame encompassing only two columns bearing\n",
    "        # the name \"variable\" and \"value\", respectively\n",
    "        # As the third column harbouring interaction information is not\n",
    "        # of interest, the DataFrame returned by `pandas.melt()` is\n",
    "        # narroed down to rows with `variable` values of 0 and 1 prior\n",
    "        # to being fed into `pandas.unique()`\n",
    "        long_format_PPIs_df = pd.melt(current_split_and_chunk_PPIs_df)\n",
    "        \n",
    "        unique_uniprot_IDs = long_format_PPIs_df[\n",
    "            (long_format_PPIs_df[\"variable\"] == 0)\n",
    "            |\n",
    "            (long_format_PPIs_df[\"variable\"] == 1)\n",
    "        ][\"value\"].unique()\n",
    "        \n",
    "        current_chunk_seqs_fasta = fasta.FastaFile()\n",
    "\n",
    "        for uniprot_ID in unique_uniprot_IDs:\n",
    "            current_chunk_seqs_fasta[uniprot_ID] = (\n",
    "                all_VACV_WR_and_human_prots_fasta[uniprot_ID]\n",
    "            )\n",
    "        \n",
    "        current_chunk_seqs_fasta.write(\n",
    "            f\"data_set_splits/data_set_split_{i}/VACV_WR_pos_and_neg_\"\n",
    "            f\"PPIs_test_set_prot_seqs_split_{i}_chunk_{j}.fasta\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
