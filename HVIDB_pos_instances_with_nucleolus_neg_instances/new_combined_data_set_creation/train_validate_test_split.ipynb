{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584dfb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe purpose of this Jupyter notebook is to perform a train-validate-test\\nsplit for the VACV WR data set. This is done as follows: Hierarchical\\nclustering is performed for the 43 VACV WR proteins involved in ...\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The purpose of this Jupyter notebook is to perform a train-validate-test\n",
    "split for the VACV WR data set. This is done as follows: Hierarchical\n",
    "clustering is performed for the 43 VACV WR proteins involved in ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b999afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c848e",
   "metadata": {},
   "source": [
    "### Retrieve PPI information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3cfd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PPI information from the CSV file\n",
    "path_to_PPIs_csv = \"all_HVIDB_VACV_WR_interactions.csv\"\n",
    "all_VACV_WR_PPIs_df = pd.read_csv(path_to_PPIs_csv)\n",
    "\n",
    "# Extract the PPIs in the form of tuples\n",
    "human_int_partners = [\n",
    "    interaction_pair.split(\"-\")[0]\n",
    "    for interaction_pair in all_VACV_WR_PPIs_df[\"Human-virus PPI\"]\n",
    "]\n",
    "VACV_WR_int_partners = [\n",
    "    interaction_pair.split(\"-\")[1]\n",
    "    for interaction_pair in all_VACV_WR_PPIs_df[\"Human-virus PPI\"]\n",
    "]\n",
    "\n",
    "ppi_list = [\n",
    "    (human_prot, vacv_prot)\n",
    "    for human_prot, vacv_prot \n",
    "    in zip(human_int_partners, VACV_WR_int_partners)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d43031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     343\n",
      "\n",
      "1     2\n",
      "\n",
      "2     1\n",
      "\n",
      "3     2\n",
      "\n",
      "4     10\n",
      "\n",
      "5     1\n",
      "\n",
      "6     5\n",
      "\n",
      "7     3\n",
      "\n",
      "8     15\n",
      "\n",
      "9     2\n",
      "\n",
      "10    2\n",
      "\n",
      "11    1\n",
      "\n",
      "12    1\n",
      "\n",
      "13    1\n",
      "\n",
      "14    1\n",
      "\n",
      "15    7\n",
      "\n",
      "16    5\n",
      "\n",
      "17    3\n",
      "\n",
      "18    1\n",
      "\n",
      "19    2\n",
      "\n",
      "20    1\n",
      "\n",
      "21    1\n",
      "\n",
      "22    2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(ppi_list)\n",
    "components = list(nx.connected_components(G))\n",
    "\n",
    "for i, component in enumerate(components):\n",
    "    # For each component, determine the amount of PPIs\n",
    "    print(\n",
    "        str(i).ljust(5),\n",
    "        sum([\n",
    "            human_int_partners.count(prot) for prot in component\n",
    "        ])\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40f4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of PPIs: 412\n",
      "\n",
      "The portion of the PPIs assigned to the training set is 0.833 (343 of 412).\n",
      "The portion of the PPIs assigned to the validation set is 0.0825 (34 of 412).\n",
      "The portion of the PPIs assigned to the test set is 0.085 (35 of 412).\n"
     ]
    }
   ],
   "source": [
    "total_n_ppis = sum([\n",
    "    343, 2, 1, 2, 10, 1, 5, 3, 15, 2, 2, 1, 1, 1, 1, 7, 5, 3, 1, 2, 1,\n",
    "    1, 2\n",
    "])\n",
    "print(\n",
    "    f\"Total amount of PPIs: {total_n_ppis}\"\n",
    ")\n",
    "print()\n",
    "print(\n",
    "    \"The portion of the PPIs assigned to the training set is \"\n",
    "    f\"{343/total_n_ppis:.3} (343 of {total_n_ppis}).\"\n",
    ")\n",
    "\n",
    "# The sum of the remaining PPIs is 69; thus, an attempt is made to\n",
    "# assign approximately 35 PPIs to the remaining two sets each\n",
    "# (validation and test set)\n",
    "print(\n",
    "    \"The portion of the PPIs assigned to the validation set is \"\n",
    "    f\"{(10 + 5 + 2 + 1 + 1 + 5 + 2 + 3 + 2 + 3)/total_n_ppis:.3} \"\n",
    "    f\"({10 + 5 + 2 + 1 + 1 + 5 + 2 + 3 + 2 + 3} of 412).\"\n",
    ")\n",
    "print(\n",
    "    \"The portion of the PPIs assigned to the test set is \"\n",
    "    f\"{(15 + 2 + 1 + 1 + 7 + 1 + 1 + 1 + 2 + 2 + 1 + 1)/total_n_ppis:.3} \"\n",
    "    f\"({15 + 2 + 1 + 1 + 7 + 1 + 1 + 1 + 2 + 2 + 1 + 1} of 412).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8aea2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325242718446602\n",
      "0.0825242718446602\n",
      "0.08495145631067962\n"
     ]
    }
   ],
   "source": [
    "# When aiming for balance between the two classes (positive and negative\n",
    "# PPIs), the proportions remain the same\n",
    "training_factor = 2\n",
    "val_factor = 2\n",
    "test_factor = 2\n",
    "\n",
    "print(\n",
    "    (343 * training_factor)\n",
    "    /\n",
    "    (343 * training_factor + 34 * val_factor + 35 * test_factor)\n",
    ")\n",
    "print(\n",
    "    (34 * val_factor)\n",
    "    /\n",
    "    (343 * training_factor + 34 * val_factor + 35 * test_factor)\n",
    ")\n",
    "print(\n",
    "    (35 * test_factor)\n",
    "    /\n",
    "    (343 * training_factor + 34 * val_factor + 35 * test_factor)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f16e8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990881458966566\n",
      "0.10030395136778116\n",
      "0.2006079027355623\n"
     ]
    }
   ],
   "source": [
    "# When generating twice as many negative PPI instances for each set,\n",
    "# the target proportions of 70/10/20 are satisfied fairly accurately\n",
    "print(\n",
    "    (230 * 2)\n",
    "    /\n",
    "    ((230 + 33 + 66) * 2)\n",
    ")\n",
    "\n",
    "print(\n",
    "    (33 * 2)\n",
    "    /\n",
    "    ((230 + 33 + 66) * 2)\n",
    ")\n",
    "\n",
    "print(\n",
    "    (66 * 2)\n",
    "    /\n",
    "    ((230 + 33 + 66) * 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97129c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "print(230 + 33 + 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe70a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the individual components are assigned to the three sets\n",
    "# The largest component encompassing 343 PPIs is assigned to the\n",
    "# training set\n",
    "VACV_WR_prots_training_set = list(components[0])\n",
    "\n",
    "# As a reminder, components encompassing the following amounts of PPIs\n",
    "# are assigned to the validation set:\n",
    "# 10, 5, 2, 1, 1, 5, 2, 3, 2, 3\n",
    "VACV_WR_prots_validation_set = [\n",
    "    *components[4], *components[6], *components[1], *components[2],\n",
    "    *components[5], *components[16], *components[3], *components[7],\n",
    "    *components[9], *components[17]\n",
    "]\n",
    "\n",
    "# As a reminder, components encompassing the following amounts of PPIs\n",
    "# are assigned to the test set:\n",
    "# 15, 2, 1, 1, 7, 1, 1, 1, 2, 2, 1, 1\n",
    "VACV_WR_prots_test_set = [\n",
    "    *components[8], *components[10], *components[11], *components[12],\n",
    "    *components[15], *components[13], *components[14], *components[18],\n",
    "    *components[19], *components[22], *components[20], *components[21]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e0018",
   "metadata": {},
   "source": [
    "### Hierarchical clustering of the 328 human nucleolus proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "321c6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering for the 328 human nucleolus proteins\n",
    "# To this end, the percent identity matrix for the 328 human nucleolus\n",
    "# proteins has to be loaded\n",
    "path_to_percent_ident_mat_eligible_nucleolus_prots = (\n",
    "    \"percent_identity_matrix_by_clustal_omega_eligible_human_nucleolus_\"\n",
    "    \"proteins_max_length_1700_AAs.pkl\"\n",
    ")\n",
    "\n",
    "with open(path_to_percent_ident_mat_eligible_nucleolus_prots, \"rb\") as f:\n",
    "    (\n",
    "        nucleolus_identifier_list,\n",
    "        percent_ident_mat_nucleolus\n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80bb51f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 328)\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    (percent_ident_mat_nucleolus.shape[0] == 328)\n",
    "    and\n",
    "    (percent_ident_mat_nucleolus.shape[1] == 328)\n",
    ")\n",
    "\n",
    "print(percent_ident_mat_nucleolus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927ac68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering requires a distance matrix\n",
    "# Thus, the percent identity matrix has to be converted into a distance\n",
    "# matrix by subtracting the identity value from 100 (i.e. 100 - percent\n",
    "# identity)\n",
    "nucleolus_distance_matrix = 100 - percent_ident_mat_nucleolus\n",
    "\n",
    "assert (\n",
    "    (np.min(nucleolus_distance_matrix) == 0)\n",
    "    and\n",
    "    (np.max(nucleolus_distance_matrix) == 100)\n",
    ")\n",
    "\n",
    "# Convert to condensed distance matrix for clustering\n",
    "nucleolus_condensed_dist_mat = squareform(nucleolus_distance_matrix)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(nucleolus_condensed_dist_mat, method=\"average\")\n",
    "\n",
    "# Form flat clusters from the hierarchical clustering\n",
    "cluster_labels = fcluster(\n",
    "    Z,\n",
    "    t=92,\n",
    "    criterion=\"distance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21619bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "1     3\n",
      "2     8\n",
      "3     53\n",
      "4     48\n",
      "5     17\n",
      "6     6\n",
      "7     11\n",
      "8     172\n",
      "9     2\n",
      "10    4\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(cluster_labels))\n",
    "print()\n",
    "for label in np.unique(cluster_labels):\n",
    "    print(str(label).ljust(5), cluster_labels.tolist().count(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08534243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually assign the clusters to the three sets (train, validation and\n",
    "# test)\n",
    "# An attempt is made to match the proportions of the VACV WR proteins,\n",
    "# i.e. 83% for the training set (272 proteins) and 8.5% for the\n",
    "# validation and test set each (28 proteins)\n",
    "nucleolus_prots_training_set = np.array(nucleolus_identifier_list)[\n",
    "    (cluster_labels == 8)\n",
    "    |\n",
    "    (cluster_labels == 3)\n",
    "    |\n",
    "    (cluster_labels == 4)\n",
    "]\n",
    "\n",
    "nucleolus_prots_validation_set = np.array(nucleolus_identifier_list)[\n",
    "    (cluster_labels == 6)\n",
    "    |\n",
    "    (cluster_labels == 7)\n",
    "    |\n",
    "    (cluster_labels == 9)\n",
    "    |\n",
    "    (cluster_labels == 10)\n",
    "    |\n",
    "    (cluster_labels == 11)\n",
    "    |\n",
    "    (cluster_labels == 12)\n",
    "    |\n",
    "    (cluster_labels == 13)\n",
    "    |\n",
    "    (cluster_labels == 14)\n",
    "]\n",
    "\n",
    "nucleolus_prots_test_set = np.array(nucleolus_identifier_list)[\n",
    "    (cluster_labels == 1)\n",
    "    |\n",
    "    (cluster_labels == 2)\n",
    "    |\n",
    "    (cluster_labels == 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3828b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(nucleolus_prots_training_set))\n",
    "print(len(nucleolus_prots_validation_set))\n",
    "print(len(nucleolus_prots_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23fb86",
   "metadata": {},
   "source": [
    "### Construction of the PPI data set/the negative PPI instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3084072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a first step, generate a separate file for the training, validation\n",
    "# and test set each\n",
    "# Start with the training set\n",
    "train_set_human_col = np.array(human_int_partners)[\n",
    "    np.isin(np.array(VACV_WR_int_partners), VACV_WR_prots_training_set)\n",
    "]\n",
    "train_set_VACV_col = np.array(VACV_WR_int_partners)[\n",
    "    np.isin(np.array(VACV_WR_int_partners), VACV_WR_prots_training_set)\n",
    "]\n",
    "\n",
    "assert len(train_set_human_col) == len(train_set_VACV_col)\n",
    "\n",
    "train_set_label_col = [1] * len(train_set_human_col)\n",
    "\n",
    "# Address the validation set\n",
    "validation_set_human_col = np.array(human_int_partners)[\n",
    "    np.isin(np.array(VACV_WR_int_partners), VACV_WR_prots_validation_set)\n",
    "]\n",
    "validation_set_VACV_col = np.array(VACV_WR_int_partners)[\n",
    "    np.isin(np.array(VACV_WR_int_partners), VACV_WR_prots_validation_set)\n",
    "]\n",
    "\n",
    "assert len(validation_set_human_col) == len(validation_set_VACV_col)\n",
    "\n",
    "validation_set_label_col = [1] * len(validation_set_human_col)\n",
    "\n",
    "# Address the test set\n",
    "test_set_human_col = np.array(human_int_partners)[\n",
    "    np.isin(np.array(VACV_WR_int_partners), VACV_WR_prots_test_set)\n",
    "]\n",
    "test_set_VACV_col = np.array(VACV_WR_int_partners)[\n",
    "    np.isin(np.array(VACV_WR_int_partners), VACV_WR_prots_test_set)\n",
    "]\n",
    "\n",
    "assert len(test_set_human_col) == len(test_set_VACV_col)\n",
    "\n",
    "test_set_label_col = [1] * len(test_set_human_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "746a2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    len(train_set_human_col)\n",
    "    ==\n",
    "    len(train_set_VACV_col)\n",
    "    ==\n",
    "    len(train_set_label_col)\n",
    "    ==\n",
    "    343\n",
    ")\n",
    "\n",
    "assert (\n",
    "    len(validation_set_human_col)\n",
    "    ==\n",
    "    len(validation_set_VACV_col)\n",
    "    ==\n",
    "    len(validation_set_label_col)\n",
    "    ==\n",
    "    34\n",
    ")\n",
    "\n",
    "assert (\n",
    "    len(test_set_human_col)\n",
    "    ==\n",
    "    len(test_set_VACV_col)\n",
    "    ==\n",
    "    len(test_set_label_col)\n",
    "    ==\n",
    "    35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1282b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the VACV WR UniProt accessions for each set (training,\n",
    "# validation and test)\n",
    "# Training set\n",
    "VACV_WR_prots_assigned_to_training_set = []\n",
    "\n",
    "for prot in VACV_WR_prots_training_set:\n",
    "    if prot in VACV_WR_int_partners:\n",
    "        VACV_WR_prots_assigned_to_training_set.append(prot)\n",
    "\n",
    "# Validation set\n",
    "VACV_WR_prots_assigned_to_validation_set = []\n",
    "\n",
    "for prot in VACV_WR_prots_validation_set:\n",
    "    if prot in VACV_WR_int_partners:\n",
    "        VACV_WR_prots_assigned_to_validation_set.append(prot)\n",
    "\n",
    "# Test set\n",
    "VACV_WR_prots_assigned_to_test_set = []\n",
    "\n",
    "for prot in VACV_WR_prots_test_set:\n",
    "    if prot in VACV_WR_int_partners:\n",
    "        VACV_WR_prots_assigned_to_test_set.append(prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8aeeeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of VACV WR proteins assigned to the training set: 20\n",
      "Amount of VACV WR proteins assigned to the validation set: 11\n",
      "Amount of VACV WR proteins assigned to the test set: 12\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Amount of VACV WR proteins assigned to the training set: \"\n",
    "    f\"{len(VACV_WR_prots_assigned_to_training_set):,}\"\n",
    ")\n",
    "print(\n",
    "    \"Amount of VACV WR proteins assigned to the validation set: \"\n",
    "    f\"{len(VACV_WR_prots_assigned_to_validation_set):,}\"\n",
    ")\n",
    "print(\n",
    "    \"Amount of VACV WR proteins assigned to the test set: \"\n",
    "    f\"{len(VACV_WR_prots_assigned_to_test_set):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa077f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "# Address the construction of negative PPI instances\n",
    "# The two classes (positive and negative PPIs) are supposed to be\n",
    "# balanced, i.e. the ratio between positive and negative PPIs is\n",
    "# supposed to be 1:1\n",
    "# Begin with the training set; the training set encompasses 343 positive\n",
    "# PPIs; thus, 343 negative PPIs must be generated\n",
    "# 273 human nucleolus proteins have been assigned to the training set\n",
    "# Therefore, these 273 nucleolus proteins as well as the first 70 of\n",
    "# them are randomly paired with the VACV WR proteins assigned to this\n",
    "# set\n",
    "train_set_human_col = train_set_human_col.tolist()\n",
    "train_set_human_col += nucleolus_prots_training_set.tolist()\n",
    "train_set_human_col += nucleolus_prots_training_set.tolist()[:70]\n",
    "\n",
    "train_set_VACV_col = train_set_VACV_col.tolist()\n",
    "train_set_VACV_col += [\n",
    "    random.choice(VACV_WR_prots_assigned_to_training_set)\n",
    "    for _ in range(343)\n",
    "]\n",
    "\n",
    "train_set_label_col += [0] * 343\n",
    "\n",
    "assert (\n",
    "    len(train_set_human_col)\n",
    "    ==\n",
    "    len(train_set_VACV_col)\n",
    "    ==\n",
    "    len(train_set_label_col)\n",
    "    ==\n",
    "    343 * 2\n",
    ")\n",
    "\n",
    "# Turn to the validation set; the validation set encompasses 34 positive\n",
    "# PPIs; thus, 34 negative PPIs must be generated\n",
    "# 27 human nucleolus proteins have been assigned to the validation set\n",
    "# Therefore, these 27 nucleolus proteins as well as the first 7 of them\n",
    "# are randomly paired with the VACV WR proteins assigned to this set\n",
    "validation_set_human_col = validation_set_human_col.tolist()\n",
    "validation_set_human_col += nucleolus_prots_validation_set.tolist()\n",
    "validation_set_human_col += nucleolus_prots_validation_set.tolist()[:7]\n",
    "\n",
    "validation_set_VACV_col = validation_set_VACV_col.tolist()\n",
    "validation_set_VACV_col += [\n",
    "    random.choice(VACV_WR_prots_assigned_to_validation_set)\n",
    "    for _ in range(34)\n",
    "]\n",
    "\n",
    "validation_set_label_col += [0] * 34\n",
    "\n",
    "assert (\n",
    "    len(validation_set_human_col)\n",
    "    ==\n",
    "    len(validation_set_VACV_col)\n",
    "    ==\n",
    "    len(validation_set_label_col)\n",
    "    ==\n",
    "    34 * 2\n",
    ")\n",
    "\n",
    "# Finally, deal with the test set; the test set encompasses 35 positive\n",
    "# PPIs; thus, 35 negative PPIs must be generated\n",
    "# 28 human nucleolus proteins have been assigned to the test set\n",
    "# Therefore, these 28 nucleolus proteins as well as the first 7 of them\n",
    "# are randomly paired with the VACV WR proteins assigned to this set\n",
    "test_set_human_col = test_set_human_col.tolist()\n",
    "test_set_human_col += nucleolus_prots_test_set.tolist()\n",
    "test_set_human_col += nucleolus_prots_test_set.tolist()[:7]\n",
    "\n",
    "test_set_VACV_col = test_set_VACV_col.tolist()\n",
    "test_set_VACV_col += [\n",
    "    random.choice(VACV_WR_prots_assigned_to_test_set)\n",
    "    for _ in range(35)\n",
    "]\n",
    "\n",
    "test_set_label_col += [0] * 35\n",
    "\n",
    "assert (\n",
    "    len(test_set_human_col)\n",
    "    ==\n",
    "    len(test_set_VACV_col)\n",
    "    ==\n",
    "    len(test_set_label_col)\n",
    "    ==\n",
    "    35 * 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1c3c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a last sanity check, verify that the three sets (training,\n",
    "# validation and test) are disjoint from one another, i.e. each protein\n",
    "# occurs exclusively in one set\n",
    "uniprot_accs_in_train_set = set(\n",
    "    train_set_human_col + train_set_VACV_col\n",
    ")\n",
    "uniprot_accs_in_validation_set = set(\n",
    "    validation_set_human_col + validation_set_VACV_col\n",
    ")\n",
    "uniprot_accs_in_test_set = set(\n",
    "    test_set_human_col + test_set_VACV_col\n",
    ")\n",
    "\n",
    "assert (\n",
    "    len(uniprot_accs_in_train_set & uniprot_accs_in_validation_set) == 0\n",
    "    and\n",
    "    len(uniprot_accs_in_train_set & uniprot_accs_in_test_set) == 0\n",
    "    and\n",
    "    len(uniprot_accs_in_validation_set & uniprot_accs_in_test_set) == 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e0b9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save the PPIs per set to a TSV file\n",
    "import os\n",
    "\n",
    "data_set_dir = \"data_set_files\"\n",
    "if not os.path.exists(data_set_dir):\n",
    "    os.makedirs(data_set_dir)\n",
    "\n",
    "# Address the train set\n",
    "train_set_data = {\n",
    "    \"Human_prot\": train_set_human_col,\n",
    "    \"VACV_prot\": train_set_VACV_col,\n",
    "    \"label\": train_set_label_col\n",
    "}\n",
    "\n",
    "train_set_df = pd.DataFrame(data=train_set_data)\n",
    "\n",
    "train_set_df.to_csv(\n",
    "    os.path.join(data_set_dir, \"bullet-proof_training_set.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Address the validation set\n",
    "validation_set_data = {\n",
    "    \"Human_prot\": validation_set_human_col,\n",
    "    \"VACV_prot\": validation_set_VACV_col,\n",
    "    \"label\": validation_set_label_col\n",
    "}\n",
    "\n",
    "validation_set_df = pd.DataFrame(data=validation_set_data)\n",
    "\n",
    "validation_set_df.to_csv(\n",
    "    os.path.join(data_set_dir, \"bullet-proof_validation_set.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Address the test set\n",
    "test_set_data = {\n",
    "    \"Human_prot\": test_set_human_col,\n",
    "    \"VACV_prot\": test_set_VACV_col,\n",
    "    \"label\": test_set_label_col\n",
    "}\n",
    "\n",
    "test_set_df = pd.DataFrame(data=test_set_data)\n",
    "\n",
    "test_set_df.to_csv(\n",
    "    os.path.join(data_set_dir, \"bullet-proof_test_set.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83f5a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a last step, merge all three sets and create a combined TSV file\n",
    "entire_ppi_set_df = pd.concat(\n",
    "    [train_set_df, validation_set_df, test_set_df]\n",
    ")\n",
    "\n",
    "assert (\n",
    "    len(entire_ppi_set_df)\n",
    "    ==\n",
    "    (\n",
    "        len(train_set_df)\n",
    "        +\n",
    "        len(validation_set_df)\n",
    "        +\n",
    "        len(test_set_df)\n",
    "    )\n",
    ")\n",
    "\n",
    "entire_ppi_set_df.to_csv(\n",
    "    os.path.join(data_set_dir, \"entire_bullet-proof_ppi_data_set.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de297755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
