{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe purpose of this Jupyter notebook is to generate an interaction\\nmatrix based on PPI data obtained from the STRING database. The\\ninteraction matrix is a symmetric matrix with its row and column\\npositions corresponding to one protein each. It is a binary matrix, i.e.\\nexclusively populated with the values 0 and 1, indicating the absence or\\nthe presence of a PPI, respectively.\\n\\nMoreover, a confidence score matrix is generated. The confidence score\\nmatrix is similar to the binary interaction matrix, but differs from it\\nin that it is populated with confidence scores rather than just the\\nvalue 1 in case of a recorded interaction.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The purpose of this Jupyter notebook is to generate an interaction\n",
    "matrix based on PPI data obtained from the STRING database. The\n",
    "interaction matrix is a symmetric matrix with its row and column\n",
    "positions corresponding to one protein each. It is a binary matrix, i.e.\n",
    "exclusively populated with the values 0 and 1, indicating the absence or\n",
    "the presence of a PPI, respectively.\n",
    "\n",
    "Moreover, a confidence score matrix is generated. The confidence score\n",
    "matrix is similar to the binary interaction matrix, but differs from it\n",
    "in that it is populated with confidence scores rather than just the\n",
    "value 1 in case of a recorded interaction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0A075B749\n",
      "A0A0D9SG04\n",
      "A0A0J9YX62\n",
      "A0A0U1RRM6\n",
      "A0A1B0GTL5\n",
      "A0A2R8Y5A3\n",
      "A0A3B3IRW5\n",
      "A0A3B3IS91\n",
      "A0A3B3ISQ4\n",
      "A0N0N7\n",
      "A0N0Q3\n",
      "A3KPC7\n",
      "A4D1E9\n",
      "A4FTV9\n",
      "A6NFX8\n",
      "A6NHQ2\n",
      "A6NNZ2\n",
      "A7MCY6\n",
      "A8ASI8\n",
      "A8MPP1\n",
      "A8MUS3\n",
      "B2R4P9\n",
      "B2R4R0\n",
      "B2R4S9\n",
      "B2RDW1\n",
      "B2ZZ89\n",
      "B4DJ51\n",
      "B4DLJ1\n",
      "B8ZZN6\n",
      "C9JQJ2\n",
      "D9YZV4\n",
      "D9ZGF2\n",
      "E5KTA5\n",
      "E9KL37\n",
      "E9PDI4\n",
      "F4ZW62\n",
      "F8VVA7\n",
      "F8VXC8\n",
      "F8VZQ9\n",
      "F8WBV6\n",
      "G3V5R9\n",
      "G5E9I4\n",
      "H3BSR6\n",
      "I0J062\n",
      "J3QK89\n",
      "K7EQ78\n",
      "K7ERV3\n",
      "O00151\n",
      "O00159\n",
      "O00206\n",
      "O00327\n",
      "O00339\n",
      "O00391\n",
      "O00410\n",
      "O00444\n",
      "O00459\n",
      "O00488\n",
      "O00499\n",
      "O00515\n",
      "O00541\n",
      "O00566\n",
      "O00567\n",
      "O00571\n",
      "O00585\n",
      "O14578\n",
      "O14654\n",
      "O14746\n",
      "O14920\n",
      "O14933\n",
      "O14980\n",
      "O15020\n",
      "O15021\n",
      "O15037\n",
      "O15055\n",
      "O15111\n",
      "O15131\n",
      "O15160\n",
      "O15182\n",
      "O15213\n",
      "O15226\n",
      "O15265\n",
      "O15381\n",
      "O15444\n",
      "O15446\n",
      "O43143\n",
      "O43159\n",
      "O43187\n",
      "O43390\n",
      "O43521\n",
      "O43681\n",
      "O43815\n",
      "O43818\n",
      "O43823\n",
      "O60287\n",
      "O60506\n",
      "O60729\n",
      "O60814\n",
      "O60832\n",
      "O60936\n",
      "O75081\n",
      "O75113\n",
      "O75151\n",
      "O75152\n",
      "O75190\n",
      "O75312\n",
      "O75376\n",
      "O75398\n",
      "O75607\n",
      "O75618\n",
      "O75665\n",
      "O75683\n",
      "O75691\n",
      "O75817\n",
      "O75818\n",
      "O75934\n",
      "O76021\n",
      "O94763\n",
      "O94818\n",
      "O95059\n",
      "O95400\n",
      "O95453\n",
      "O95478\n",
      "O95551\n",
      "O95568\n",
      "O95602\n",
      "O95625\n",
      "O95707\n",
      "O95793\n",
      "O96004\n",
      "O96028\n",
      "P00451\n",
      "P01106\n",
      "P01579\n",
      "P01903\n",
      "P02511\n",
      "P02775\n",
      "P02776\n",
      "P03950\n",
      "P04083\n",
      "P04183\n",
      "P04439\n",
      "P04792\n",
      "P04908\n",
      "P05023\n",
      "P05141\n",
      "P05166\n",
      "P05412\n",
      "P05783\n",
      "P06733\n",
      "P06748\n",
      "P07355\n",
      "P07437\n",
      "P07910\n",
      "P08238\n",
      "P08708\n",
      "P09104\n",
      "P09132\n",
      "P09493\n",
      "P09651\n",
      "P09874\n",
      "P0C0S8\n",
      "P0CG48\n",
      "P0DI83\n",
      "P0DP23\n",
      "P0DPB6\n",
      "P0DW28\n",
      "P0DW81\n",
      "P11021\n",
      "P11142\n",
      "P11387\n",
      "P11388\n",
      "P12036\n",
      "P12111\n",
      "P12235\n",
      "P12236\n",
      "P12273\n",
      "P12277\n",
      "P13010\n",
      "P13051\n",
      "P13637\n",
      "P13861\n",
      "P13929\n",
      "P14923\n",
      "P15880\n",
      "P15924\n",
      "P16383\n",
      "P17480\n",
      "P17844\n",
      "P18583\n",
      "P19013\n",
      "P19237\n",
      "P19338\n",
      "P19388\n",
      "P19525\n",
      "P19544\n",
      "P19876\n",
      "P20042\n",
      "P20671\n",
      "P20700\n",
      "P20807\n",
      "P21359\n",
      "P22087\n",
      "P22362\n",
      "P22492\n",
      "P22531\n",
      "P22532\n",
      "P22626\n",
      "P22674\n",
      "P23025\n",
      "P23246\n",
      "P23396\n",
      "P24001\n",
      "P24539\n",
      "P25398\n",
      "P25685\n",
      "P27449\n",
      "P27695\n",
      "P27986\n",
      "P28562\n",
      "P28838\n",
      "P29375\n",
      "P29590\n",
      "P31025\n",
      "P31151\n",
      "P31327\n",
      "P33176\n",
      "P35221\n",
      "P35222\n",
      "P35268\n",
      "P35325\n",
      "P35326\n",
      "P36873\n",
      "P36954\n",
      "P38159\n",
      "P38646\n",
      "P39019\n",
      "P39023\n",
      "P39748\n",
      "P40617\n",
      "P41220\n",
      "P42224\n",
      "P42285\n",
      "P42336\n",
      "P42338\n",
      "P42677\n",
      "P42696\n",
      "P43631\n",
      "P46013\n",
      "P46087\n",
      "P46776\n",
      "P46777\n",
      "P46778\n",
      "P46781\n",
      "P46782\n",
      "P46783\n",
      "P46939\n",
      "P48788\n",
      "P49703\n",
      "P49715\n",
      "P49792\n",
      "P50552\n",
      "P51955\n",
      "P52179\n",
      "P52272\n",
      "P52292\n",
      "P52434\n",
      "P53803\n",
      "P54652\n",
      "P55265\n",
      "P55327\n",
      "P55345\n",
      "P55769\n",
      "P55957\n",
      "P56182\n",
      "P56192\n",
      "P56537\n",
      "P57053\n",
      "P57678\n",
      "P58753\n",
      "P58876\n",
      "P59047\n",
      "P61218\n",
      "P61236\n",
      "P61247\n",
      "P61571\n",
      "P61572\n",
      "P61573\n",
      "P61574\n",
      "P61575\n",
      "P61576\n",
      "P61578\n",
      "P61579\n",
      "P61923\n",
      "P61978\n",
      "P62081\n",
      "P62136\n",
      "P62140\n",
      "P62241\n",
      "P62244\n",
      "P62249\n",
      "P62263\n",
      "P62266\n",
      "P62277\n",
      "P62280\n",
      "P62701\n",
      "P62750\n",
      "P62753\n",
      "P62805\n",
      "P62807\n",
      "P62847\n",
      "P62857\n",
      "P62875\n",
      "P62913\n",
      "P62979\n",
      "P63010\n",
      "P63165\n",
      "P67809\n",
      "P68104\n",
      "P68371\n",
      "P68431\n",
      "P78316\n",
      "P78344\n",
      "P78345\n",
      "P78346\n",
      "P78423\n",
      "P78527\n",
      "P78563\n",
      "P82979\n",
      "P84101\n",
      "P84243\n",
      "P86452\n",
      "P98179\n",
      "Q00325\n",
      "Q00610\n",
      "Q00839\n",
      "Q00987\n",
      "Q01082\n",
      "Q01780\n",
      "Q01850\n",
      "Q01955\n",
      "Q02539\n",
      "Q02880\n",
      "Q03252\n",
      "Q05086\n",
      "Q05639\n",
      "Q05952\n",
      "Q05BQ5\n",
      "Q06265\n",
      "Q06481\n",
      "Q06787\n",
      "Q07021\n",
      "Q07666\n",
      "Q07812\n",
      "Q07866\n",
      "Q08211\n",
      "Q08379\n",
      "Q08752\n",
      "Q08945\n",
      "Q08AE8\n",
      "Q08J23\n",
      "Q0WX57\n",
      "Q12788\n",
      "Q12905\n",
      "Q12906\n",
      "Q13085\n",
      "Q13162\n",
      "Q13227\n",
      "Q13283\n",
      "Q13427\n",
      "Q13428\n",
      "Q13601\n",
      "Q13610\n",
      "Q13618\n",
      "Q13753\n",
      "Q13794\n",
      "Q13823\n",
      "Q13868\n",
      "Q13885\n",
      "Q13895\n",
      "Q13901\n",
      "Q14103\n",
      "Q14137\n",
      "Q14141\n",
      "Q14146\n",
      "Q14191\n",
      "Q14331\n",
      "Q14444\n",
      "Q14527\n",
      "Q14684\n",
      "Q14690\n",
      "Q14692\n",
      "Q14978\n",
      "Q15024\n",
      "Q15050\n",
      "Q15057\n",
      "Q15061\n",
      "Q15084\n",
      "Q15155\n",
      "Q15233\n",
      "Q15269\n",
      "Q15361\n",
      "Q15397\n",
      "Q15572\n",
      "Q15573\n",
      "Q15643\n",
      "Q15646\n",
      "Q15797\n",
      "Q15853\n",
      "Q16543\n",
      "Q16611\n",
      "Q16695\n",
      "Q16777\n",
      "Q16790\n",
      "Q1ED39\n",
      "Q2NL82\n",
      "Q2TBE0\n",
      "Q3B726\n",
      "Q3ZCM7\n",
      "Q496M5\n",
      "Q49MI3\n",
      "Q4G0J3\n",
      "Q504T8\n",
      "Q53GL7\n",
      "Q53H80\n",
      "Q53HL2\n",
      "Q53SF7\n",
      "Q53T94\n",
      "Q548T7\n",
      "Q5C9Z4\n",
      "Q5EBL4\n",
      "Q5EE01\n",
      "Q5F1R6\n",
      "Q5H9S7\n",
      "Q5JRA6\n",
      "Q5JTH9\n",
      "Q5JVS0\n",
      "Q5QJE6\n",
      "Q5QNW6\n",
      "Q5RKV6\n",
      "Q5SY16\n",
      "Q5T5X7\n",
      "Q5T8A7\n",
      "Q5TAP6\n",
      "Q5VTE0\n",
      "Q5VU43\n",
      "Q66GS9\n",
      "Q66PJ3\n",
      "Q68CQ4\n",
      "Q68D10\n",
      "Q69383\n",
      "Q6FI13\n",
      "Q6NS38\n",
      "Q6NW34\n",
      "Q6NYC1\n",
      "Q6P0Q8\n",
      "Q6P2H3\n",
      "Q6P597\n",
      "Q6P5S2\n",
      "Q6RFH5\n",
      "Q6T310\n",
      "Q6UWP8\n",
      "Q6UWU4\n",
      "Q6ZN17\n",
      "Q6ZN40\n",
      "Q6ZQX7\n",
      "Q6ZVD7\n",
      "Q71DI3\n",
      "Q71U36\n",
      "Q76FK4\n",
      "Q76M96\n",
      "Q7L622\n",
      "Q7L7L0\n",
      "Q7Z2E3\n",
      "Q7Z333\n",
      "Q7Z406\n",
      "Q7Z6E9\n",
      "Q7Z6J9\n",
      "Q7Z7A1\n",
      "Q86UE4\n",
      "Q86US8\n",
      "Q86VP6\n",
      "Q86W54\n",
      "Q86WX3\n",
      "Q86X95\n",
      "Q86YZ3\n",
      "Q8IUC6\n",
      "Q8IUF8\n",
      "Q8IUR0\n",
      "Q8IV48\n",
      "Q8IVF2\n",
      "Q8IWA0\n",
      "Q8IWS0\n",
      "Q8IWX8\n",
      "Q8IXT5\n",
      "Q8IY37\n",
      "Q8IY57\n",
      "Q8IY81\n",
      "Q8IZ02\n",
      "Q8IZL8\n",
      "Q8IZU1\n",
      "Q8N0T1\n",
      "Q8N3Z6\n",
      "Q8N567\n",
      "Q8N6M6\n",
      "Q8N726\n",
      "Q8N8A6\n",
      "Q8N8Q3\n",
      "Q8N8S7\n",
      "Q8NCD3\n",
      "Q8NCE0\n",
      "Q8ND90\n",
      "Q8NDD1\n",
      "Q8NDF8\n",
      "Q8NEJ9\n",
      "Q8NFZ5\n",
      "Q8NG50\n",
      "Q8NG66\n",
      "Q8NHM5\n",
      "Q8NI36\n",
      "Q8TAQ2\n",
      "Q8TBZ6\n",
      "Q8TDD1\n",
      "Q8TDL5\n",
      "Q8TDN6\n",
      "Q8TDR2\n",
      "Q8TE04\n",
      "Q8TED0\n",
      "Q8WTP8\n",
      "Q8WTS1\n",
      "Q8WTT2\n",
      "Q8WUM4\n",
      "Q8WV24\n",
      "Q8WW01\n",
      "Q8WW38\n",
      "Q8WWI1\n",
      "Q8WXF1\n",
      "Q8WXF8\n",
      "Q8WXH0\n",
      "Q8WYQ5\n",
      "Q8WZ33\n",
      "Q8WZ42\n",
      "Q92187\n",
      "Q92560\n",
      "Q92569\n",
      "Q92583\n",
      "Q92599\n",
      "Q92624\n",
      "Q92737\n",
      "Q92794\n",
      "Q92841\n",
      "Q92844\n",
      "Q92876\n",
      "Q92878\n",
      "Q92934\n",
      "Q92979\n",
      "Q92993\n",
      "Q93008\n",
      "Q93077\n",
      "Q93079\n",
      "Q93086\n",
      "Q969H0\n",
      "Q969H6\n",
      "Q969X6\n",
      "Q96AH0\n",
      "Q96AY2\n",
      "Q96AZ6\n",
      "Q96B26\n",
      "Q96BK5\n",
      "Q96C34\n",
      "Q96CX3\n",
      "Q96DA0\n",
      "Q96DE0\n",
      "Q96E22\n",
      "Q96ES6\n",
      "Q96EU6\n",
      "Q96EZ8\n",
      "Q96F44\n",
      "Q96FC9\n",
      "Q96FQ6\n",
      "Q96G21\n",
      "Q96GC6\n",
      "Q96GM8\n",
      "Q96GQ7\n",
      "Q96HI0\n",
      "Q96JA1\n",
      "Q96JH7\n",
      "Q96KK5\n",
      "Q96NS1\n",
      "Q96NY9\n",
      "Q96P11\n",
      "Q96PG8\n",
      "Q96PK6\n",
      "Q96PM9\n",
      "Q96Q89\n",
      "Q96QA6\n",
      "Q96RQ9\n",
      "Q96RS0\n",
      "Q96ST3\n",
      "Q99547\n",
      "Q99575\n",
      "Q99661\n",
      "Q99675\n",
      "Q99729\n",
      "Q99836\n",
      "Q99848\n",
      "Q99877\n",
      "Q99878\n",
      "Q99879\n",
      "Q99880\n",
      "Q9BQ04\n",
      "Q9BQ39\n",
      "Q9BQ67\n",
      "Q9BQE3\n",
      "Q9BQG0\n",
      "Q9BQS8\n",
      "Q9BRK4\n",
      "Q9BRP8\n",
      "Q9BRT6\n",
      "Q9BRU9\n",
      "Q9BS26\n",
      "Q9BSC4\n",
      "Q9BSJ6\n",
      "Q9BSV6\n",
      "Q9BT92\n",
      "Q9BTM1\n",
      "Q9BUL9\n",
      "Q9BV38\n",
      "Q9BVA1\n",
      "Q9BVI4\n",
      "Q9BVJ6\n",
      "Q9BVP2\n",
      "Q9BVT8\n",
      "Q9BWF2\n",
      "Q9BWF3\n",
      "Q9BXF6\n",
      "Q9BXS6\n",
      "Q9BXY0\n",
      "Q9BYE4\n",
      "Q9BYG3\n",
      "Q9BYG7\n",
      "Q9BYP7\n",
      "Q9BZE4\n",
      "Q9C086\n",
      "Q9C0F3\n",
      "Q9GZL7\n",
      "Q9GZN1\n",
      "Q9GZR2\n",
      "Q9GZS1\n",
      "Q9GZT9\n",
      "Q9H0A0\n",
      "Q9H0D6\n",
      "Q9H0S4\n",
      "Q9H0U9\n",
      "Q9H116\n",
      "Q9H190\n",
      "Q9H2G2\n",
      "Q9H2G4\n",
      "Q9H2Y7\n",
      "Q9H334\n",
      "Q9H4A3\n",
      "Q9H4B4\n",
      "Q9H4L4\n",
      "Q9H501\n",
      "Q9H583\n",
      "Q9H5U6\n",
      "Q9H633\n",
      "Q9H6E5\n",
      "Q9H6R0\n",
      "Q9H6R4\n",
      "Q9H6S1\n",
      "Q9H6S3\n",
      "Q9H6W3\n",
      "Q9H6Y2\n",
      "Q9H7B2\n",
      "Q9H7Z3\n",
      "Q9H869\n",
      "Q9H875\n",
      "Q9H8H0\n",
      "Q9H8H2\n",
      "Q9H9L3\n",
      "Q9H9Y2\n",
      "Q9H9Y6\n",
      "Q9H9Z2\n",
      "Q9HA38\n",
      "Q9HAF1\n",
      "Q9HAJ7\n",
      "Q9HB07\n",
      "Q9HCC0\n",
      "Q9HCU9\n",
      "Q9NP64\n",
      "Q9NP74\n",
      "Q9NP98\n",
      "Q9NPD3\n",
      "Q9NPE3\n",
      "Q9NPH5\n",
      "Q9NQ29\n",
      "Q9NQ55\n",
      "Q9NQT4\n",
      "Q9NQT5\n",
      "Q9NQZ2\n",
      "Q9NR00\n",
      "Q9NR30\n",
      "Q9NRC8\n",
      "Q9NRJ3\n",
      "Q9NRQ2\n",
      "Q9NRR4\n",
      "Q9NRX1\n",
      "Q9NSA3\n",
      "Q9NSI2\n",
      "Q9NTK5\n",
      "Q9NU22\n",
      "Q9NUL3\n",
      "Q9NUQ6\n",
      "Q9NUU7\n",
      "Q9NV06\n",
      "Q9NV31\n",
      "Q9NVN8\n",
      "Q9NVP1\n",
      "Q9NVU7\n",
      "Q9NVX2\n",
      "Q9NW13\n",
      "Q9NW75\n",
      "Q9NWT1\n",
      "Q9NX24\n",
      "Q9NX58\n",
      "Q9NXF1\n",
      "Q9NXW9\n",
      "Q9NY12\n",
      "Q9NY61\n",
      "Q9NY93\n",
      "Q9NYH9\n",
      "Q9NYV6\n",
      "Q9NZ56\n",
      "Q9NZM5\n",
      "Q9P0K7\n",
      "Q9P1T7\n",
      "Q9P1U0\n",
      "Q9P258\n",
      "Q9P275\n",
      "Q9P2D1\n",
      "Q9P2P1\n",
      "Q9UBB5\n",
      "Q9UER7\n",
      "Q9UGY1\n",
      "Q9UH99\n",
      "Q9UHA3\n",
      "Q9UHB9\n",
      "Q9UIF9\n",
      "Q9UKD2\n",
      "Q9UKK9\n",
      "Q9UL40\n",
      "Q9UL41\n",
      "Q9UL42\n",
      "Q9ULW3\n",
      "Q9UMR2\n",
      "Q9UMY1\n",
      "Q9UN81\n",
      "Q9UNQ2\n",
      "Q9UNX4\n",
      "Q9UPP1\n",
      "Q9UPT5\n",
      "Q9UQ80\n",
      "Q9Y221\n",
      "Q9Y237\n",
      "Q9Y258\n",
      "Q9Y2H9\n",
      "Q9Y2L1\n",
      "Q9Y2P8\n",
      "Q9Y2R4\n",
      "Q9Y2X3\n",
      "Q9Y324\n",
      "Q9Y3A2\n",
      "Q9Y3A4\n",
      "Q9Y3A5\n",
      "Q9Y3B2\n",
      "Q9Y3B3\n",
      "Q9Y3C1\n",
      "Q9Y3C5\n",
      "Q9Y3S1\n",
      "Q9Y3S2\n",
      "Q9Y3T6\n",
      "Q9Y3T9\n",
      "Q9Y3Y2\n",
      "Q9Y463\n",
      "Q9Y4C8\n",
      "Q9Y4E1\n",
      "Q9Y4K3\n",
      "Q9Y4W2\n",
      "Q9Y4Z0\n",
      "Q9Y530\n",
      "Q9Y5J1\n",
      "Q9Y5Q9\n",
      "Q9Y5S2\n",
      "Q9Y5X3\n",
      "Q9Y618\n",
      "Q9Y657\n",
      "Q9Y679\n",
      "Q9Y6D6\n",
      "Q9Y6K9\n",
      "V9GZ56\n"
     ]
    }
   ],
   "source": [
    "# As a preliminary step, it is investigated whether all human proteins\n",
    "# involved in the human-VACV WR PPIs deposited in HVIDB are also covered\n",
    "# by the VACV WR screen at hand\n",
    "# It must be noted that the TSV file with PPI pairs contains UniProt\n",
    "# accession IDs, which are not available in every screen TSV file\n",
    "# However, STRING IDs are available\n",
    "# Thus, the UniProt accessions of the human proteins involved in HVIDB\n",
    "# PPIs are converted to STRING IDs via the ID mapping service provided\n",
    "# by UniProt (settings:\n",
    "# From database: UniProtKB AC/ID\n",
    "# To database: Protein-protein interaction databases/STRING)\n",
    "path_to_HVIDB_VACV_WR_PPIs = (\n",
    "    \"/Users/jacobanter/Documents/Code/VACV_screen/HVIDB_pos_instances_\"\n",
    "    \"with_nucleolus_neg_instances/VACV_WR_pos_and_nucleolus_prots_neg_\"\n",
    "    \"PPI_instances.tsv\"\n",
    ")\n",
    "\n",
    "HVIDB_VACV_WR_PPIs_df = pd.read_csv(\n",
    "    path_to_HVIDB_VACV_WR_PPIs,\n",
    "    sep=\"\\t\"\n",
    ")\n",
    "\n",
    "HVIDB_human_prot_IDs = np.unique(HVIDB_VACV_WR_PPIs_df[\"Human_prot\"])\n",
    "\n",
    "# Print the UniProt accessions one at a time in order to copy and paste\n",
    "# them into the ID conversion service\n",
    "for human_prot_ID in HVIDB_human_prot_IDs:\n",
    "    print(human_prot_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ID conversion service suceeded for 737 of 800 UniProt accessions\n",
    "# For the ones for which conversion failed, it is tried to identify the\n",
    "# STRING ID manually\n",
    "# The 63 UniProt accessions for which conversion failed are as follows:\n",
    "# D9ZGF2: 9606.ENSP00000295550\n",
    "# F8WBV6: 9606.ENSP00000387187\n",
    "# Q5VTE0: actually has no STRING ID\n",
    "# B2RDW1: 9606.ENSP00000272317\n",
    "# P61578: actually has no STRING ID\n",
    "# P61573: actually has no STRING ID\n",
    "# F8VZQ9: 9606.ENSP00000337632\n",
    "# E9KL37: 9606.ENSP00000344314\n",
    "# P61572: actually has no STRING ID\n",
    "# Q96KK5: 9606.ENSP00000366679\n",
    "# E9PDI4: 9606.ENSP00000375829\n",
    "# G3V5R9: 9606.ENSP00000414982\n",
    "# V9GZ56: 9606.ENSP00000469468\n",
    "# A3KPC7: 9606.ENSP00000366679\n",
    "# B2R4R0: 9606.ENSP00000244537, 9606.ENSP00000347168, 9606.ENSP00000366974, 9606.ENSP00000367034, 9606.ENSP00000443017, 9606.ENSP00000462355, 9606.ENSP00000462667, 9606.ENSP00000479106, 9606.ENSP00000479461, 9606.ENSP00000479794, 9606.ENSP00000480960, 9606.ENSP00000481486, 9606.ENSP00000484789, 9606.ENSP00000489236\n",
    "# K7ERV3: 9606.ENSP00000468425\n",
    "# F8VVA7: 9606.ENSP00000449270\n",
    "# F8VXC8: 9606.ENSP00000449396\n",
    "# G5E9I4: 9606.ENSP00000396052\n",
    "# A8MUS3: 9606.ENSP00000389103\n",
    "# B8ZZN6: 9606.ENSP00000376077\n",
    "# P61571: actually has no STRING ID\n",
    "# A8MPP1: actually has no STRING ID\n",
    "# A0A3B3IRW5: 9606.ENSP00000484803\n",
    "# A0A0U1RRM6: 9606.ENSP00000355809\n",
    "# P0DI83: 9606.ENSP00000413156\n",
    "# B2R4P9: 9606.ENSP00000254810, 9606.ENSP00000355780\n",
    "# P61574: actually has no STRING ID\n",
    "# A0N0Q3: 9606.ENSP00000354416\n",
    "# P0DW81: actually has no STRING ID\n",
    "# A8ASI8: 9606.ENSP00000318822\n",
    "# J3QK89: 9606.ENSP00000439856\n",
    "# P0DW28: actually has no STRING ID\n",
    "# Q6ZN40: 9606.ENSP00000351022\n",
    "# B4DJ51: 9606.ENSP00000291295, 9606.ENSP00000499717, 9606.ENSP00000499797\n",
    "# E5KTA5: 9606.ENSP00000242576\n",
    "# F4ZW62: 9606.ENSP00000355011\n",
    "# A0A0D9SG04: 9606.ENSP00000487041\n",
    "# A0A3B3IS91: 9606.ENSP00000399851\n",
    "# B2ZZ89: 9606.ENSP00000349259\n",
    "# I0J062: 9606.ENSP00000479258\n",
    "# A0A2R8Y5A3: 9606.ENSP00000495360\n",
    "# P61579: actually has no STRING ID\n",
    "# A4FTV9: 9606.ENSP00000351589, 9606.ENSP00000352119, 9606.ENSP00000352627, 9606.ENSP00000482431, 9606.ENSP00000482538\n",
    "# P43631: actually has no STRING ID\n",
    "# Q8N726: 9606.ENSP00000418915\n",
    "# A6NFX8: 9606.ENSP00000419628\n",
    "# H3BSR6: 9606.ENSP00000006053\n",
    "# Q548T7: 9606.ENSP00000484803, 9606.ENSP00000497585\n",
    "# A0A075B749: 9606.ENSP00000358363\n",
    "# A0A3B3ISQ4: 9606.ENSP00000435585\n",
    "# B4DLJ1: 9606.ENSP00000222305\n",
    "# P35325: 9606.ENSP00000357744\n",
    "# Q9UN81: actually has no STRING ID\n",
    "# A0N0N7: 9606.ENSP00000006053\n",
    "# B2R4S9: 9606.ENSP00000321744, 9606.ENSP00000348924, 9606.ENSP00000366962, 9606.ENSP00000445633, 9606.ENSP00000489317\n",
    "# Q69383: actually has no STRING ID\n",
    "# A0A1B0GTL5: 9606.ENSP00000258098\n",
    "# K7EQ78: 9606.ENSP00000225328\n",
    "# A0A0J9YX62: 9606.ENSP00000262177\n",
    "# D9YZV4: 9606.ENSP00000351022\n",
    "# P61576: actually has no STRING ID\n",
    "# P61575: actually has no STRING ID\n",
    "# These manually found STRING IDs are added to the ID conversion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also verify that each UniProt accession in the screen TSV file is\n",
    "# correct\n",
    "# To this end, a file has been downloaded from the STRING database\n",
    "# assigning STRING IDs to UniProt accessions (in that file, the UniProt\n",
    "# accession is denoted by \"UniProt_AC\")\n",
    "# The abovementioned file from STRING is a TSV file\n",
    "path_to_STRING_ID_assignments_file = \"9606.protein.aliases.v12.0.txt\"\n",
    "STRING_ID_assignments_df = pd.read_csv(\n",
    "    path_to_STRING_ID_assignments_file,\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/64kbg_f11z97kx1dw__420vh0000gn/T/ipykernel_2850/935070110.py:8: DtypeWarning: Columns (42,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  VACV_screen_df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Also load the latest version of the screen TSV file\n",
    "path_to_VACV_screen_report = (\n",
    "    \"/Users/jacobanter/Documents/Code/VACV_screen/VACV_Report_only_\"\n",
    "    \"valid_single_pooled_siRNA_and_esiRNA_single_entries_only_without_\"\n",
    "    \"Qiagen_mismatches.tsv\"\n",
    ")\n",
    "\n",
    "VACV_screen_df = pd.read_csv(\n",
    "    path_to_VACV_screen_report,\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 STRING IDs lacking a UniProt accession.\n",
      "2866810    A0AV79\n",
      "2866811    A0AV81\n",
      "2866925    Q8N5S3\n",
      "2866926    Q8N7V4\n",
      "Name: alias, dtype: object\n",
      "\n",
      "3508999    H3BNL1\n",
      "Name: alias, dtype: object\n",
      "\n",
      "3516707    A6NHZ3\n",
      "3516735    B4DQM8\n",
      "3516844    Q6DHV7\n",
      "Name: alias, dtype: object\n",
      "\n",
      "2645914    A8K9W3\n",
      "2645938    D6W503\n",
      "2645979    Q96LR7\n",
      "Name: alias, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In the VACV screen TSV file, not all STRING IDs are assigned to\n",
    "# UniProt accessions and not all UniProt accessions of protein-coding\n",
    "# genes are assigned to STRING IDs\n",
    "# In a first step, address STRING IDs lacking a UniProt accession\n",
    "STRING_IDs_without_uniprot_ac = VACV_screen_df.loc[\n",
    "    (VACV_screen_df[\"ID_String\"] != \"Not available\")\n",
    "    &\n",
    "    (VACV_screen_df[\"UniProt_IDs\"] == \"Not available\"),\n",
    "    \"ID_String\"\n",
    "].unique()\n",
    "\n",
    "print(\n",
    "    f\"There are {len(STRING_IDs_without_uniprot_ac)} STRING IDs lacking \"\n",
    "    \"a UniProt accession.\"\n",
    ")\n",
    "\n",
    "# For each of those STRING IDs lacking a UniProt accession, the UniProt\n",
    "# accession is looked up\n",
    "for string_id in STRING_IDs_without_uniprot_ac:\n",
    "    uniprot_ac = STRING_ID_assignments_df.loc[\n",
    "        (STRING_ID_assignments_df[\"#string_protein_id\"] == string_id)\n",
    "        &\n",
    "        (STRING_ID_assignments_df[\"source\"] == \"UniProt_AC\"),\n",
    "        \"alias\"\n",
    "    ]\n",
    "    print(uniprot_ac)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some STRING IDs are mapped to multiple UniProt accessions in the\n",
    "# STRING file\n",
    "# Unfortunately, the primary accession had to be found out manually\n",
    "lacking_uniprot_acs = [\n",
    "    \"Q8N5S3\",\n",
    "    \"H3BNL1\",\n",
    "    \"Q6DHV7\",\n",
    "    \"Q96LR7\"\n",
    "]\n",
    "\n",
    "for string_id, lacking_uniprot_ac in zip(\n",
    "    STRING_IDs_without_uniprot_ac, lacking_uniprot_acs\n",
    "):\n",
    "    VACV_screen_df.loc[\n",
    "        VACV_screen_df[\"ID_String\"] == string_id,\n",
    "        \"UniProt_IDs\"\n",
    "    ] = lacking_uniprot_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 UniProt accessions do not have an associated STRING ID.\n"
     ]
    }
   ],
   "source": [
    "# Now, UniProt accessions without an associated STRING ID are addressed\n",
    "# As the screen TSV file also encompasses ncRNA, selection must be\n",
    "# performed in conjunction with the `gene_type` column\n",
    "uniprot_acs_without_string_id = VACV_screen_df.loc[\n",
    "    (VACV_screen_df[\"ID_String\"] == \"Not available\")\n",
    "    &\n",
    "    (VACV_screen_df[\"Gene_type\"] == \"protein-coding\"),\n",
    "    \"UniProt_IDs\"\n",
    "].unique()\n",
    "\n",
    "assert \"Not available\" not in uniprot_acs_without_string_id, (\n",
    "    \"Filtering of UniProt accessions has not been done properly!\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{len(uniprot_acs_without_string_id)} UniProt accessions do not \"\n",
    "    \"have an associated STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are still 192 UniProt accessions without an associated STRING ID.\n"
     ]
    }
   ],
   "source": [
    "uniprot_acs_without_string_id_list = uniprot_acs_without_string_id.tolist()\n",
    "uniprot_acs_with_available_string_ids = []\n",
    "\n",
    "for uniprot_ac_entry in uniprot_acs_without_string_id_list:\n",
    "    # Bear in mind that some genes give rise to multiple isoforms\n",
    "    uniprot_acs = uniprot_ac_entry.split(\";\")\n",
    "    current_string_id_list = []\n",
    "\n",
    "    for uniprot_ac in uniprot_acs:\n",
    "        # Extract the corresponding STRING ID\n",
    "        string_id = STRING_ID_assignments_df.loc[\n",
    "            (STRING_ID_assignments_df[\"source\"] == \"UniProt_AC\")\n",
    "            &\n",
    "            (STRING_ID_assignments_df[\"alias\"] == uniprot_ac),\n",
    "            \"#string_protein_id\"\n",
    "        ]\n",
    "    \n",
    "        if len(string_id) == 0:\n",
    "            continue\n",
    "\n",
    "        string_id = string_id.iloc[0]\n",
    "\n",
    "        current_string_id_list.append(string_id)\n",
    "    \n",
    "    if len(current_string_id_list) == 0:\n",
    "        continue\n",
    "    \n",
    "    string_id = \";\".join(current_string_id_list)\n",
    "    \n",
    "    VACV_screen_df.loc[\n",
    "        VACV_screen_df[\"UniProt_IDs\"] == uniprot_ac_entry,\n",
    "        \"ID_String\"\n",
    "    ] = string_id\n",
    "\n",
    "    uniprot_acs_with_available_string_ids.append(uniprot_ac_entry)\n",
    "\n",
    "uniprot_acs_without_string_id_list = list(\n",
    "    set(uniprot_acs_without_string_id_list)\n",
    "    -\n",
    "    set(uniprot_acs_with_available_string_ids)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"There are still {len(uniprot_acs_without_string_id_list)} \"\n",
    "    \"UniProt accessions without an associated STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are still 88 UniProt accessions without an associated STRING ID.\n"
     ]
    }
   ],
   "source": [
    "# For some UniProt accessions, the term \"Ensembl_UniProt\" is used in the\n",
    "# STRING file\n",
    "uniprot_acs_with_available_string_ids = []\n",
    "\n",
    "for uniprot_ac_entry in uniprot_acs_without_string_id_list:\n",
    "    uniprot_acs = uniprot_ac_entry.split(\";\")\n",
    "\n",
    "    current_string_id_list = []\n",
    "\n",
    "    for uniprot_ac in uniprot_acs:\n",
    "        string_id = STRING_ID_assignments_df.loc[\n",
    "            (STRING_ID_assignments_df[\"source\"] == \"Ensembl_UniProt\")\n",
    "            &\n",
    "            (STRING_ID_assignments_df[\"alias\"] == uniprot_ac),\n",
    "            \"#string_protein_id\"\n",
    "        ]\n",
    "\n",
    "        if len(string_id) == 0:\n",
    "            continue\n",
    "\n",
    "        string_id = string_id.iloc[0]\n",
    "\n",
    "        current_string_id_list.append(string_id)\n",
    "    \n",
    "    if len(current_string_id_list) == 0:\n",
    "        continue\n",
    "    \n",
    "    string_id = \";\".join(current_string_id_list)\n",
    "\n",
    "    VACV_screen_df.loc[\n",
    "        VACV_screen_df[\"UniProt_IDs\"] == uniprot_ac_entry,\n",
    "        \"ID_String\"\n",
    "    ] = string_id\n",
    "\n",
    "    uniprot_acs_with_available_string_ids.append(uniprot_ac_entry)\n",
    "\n",
    "uniprot_acs_without_string_id_list = list(\n",
    "    set(uniprot_acs_without_string_id_list)\n",
    "    -\n",
    "    set(uniprot_acs_with_available_string_ids)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"There are still {len(uniprot_acs_without_string_id_list)} \"\n",
    "    \"UniProt accessions without an associated STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5TI25\n",
      "Q9H7T3\n",
      "Q6L8H1\n",
      "A6NER0\n"
     ]
    }
   ],
   "source": [
    "# Determine whether there are still UniProt accessions with STRING IDs\n",
    "for uniprot_ac in uniprot_acs_without_string_id_list:\n",
    "    if uniprot_ac in STRING_ID_assignments_df[\"alias\"].values:\n",
    "        print(uniprot_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are still 84 UniProt accessions without an associated STRING ID.\n"
     ]
    }
   ],
   "source": [
    "# There indeed still are UniProt accessions with STRING IDs\n",
    "# Upon closer scrutiny, it emerges that the remaining four UniProt\n",
    "# accessions are given by the \"Ensembl_HGNC_uniprot_ids\" source in the\n",
    "# STRING file\n",
    "uniprot_acs_with_available_string_ids = []\n",
    "\n",
    "for uniprot_ac_entry in uniprot_acs_without_string_id_list:\n",
    "    uniprot_acs = uniprot_ac_entry.split(\";\")\n",
    "\n",
    "    current_string_id_list = []\n",
    "\n",
    "    for uniprot_ac in uniprot_acs:\n",
    "        string_id = STRING_ID_assignments_df.loc[\n",
    "            (STRING_ID_assignments_df[\"source\"]\n",
    "            ==\n",
    "            \"Ensembl_HGNC_uniprot_ids\")\n",
    "            &\n",
    "            (STRING_ID_assignments_df[\"alias\"] == uniprot_ac),\n",
    "            \"#string_protein_id\"\n",
    "        ]\n",
    "\n",
    "        if len(string_id) == 0:\n",
    "            continue\n",
    "\n",
    "        string_id = string_id.iloc[0]\n",
    "\n",
    "        current_string_id_list.append(string_id)\n",
    "    \n",
    "    if len(current_string_id_list) == 0:\n",
    "        continue\n",
    "\n",
    "    string_id = \";\".join(current_string_id_list)\n",
    "\n",
    "    VACV_screen_df.loc[\n",
    "        VACV_screen_df[\"UniProt_IDs\"] == uniprot_ac_entry,\n",
    "        \"ID_String\"\n",
    "    ] = string_id\n",
    "\n",
    "    uniprot_acs_with_available_string_ids.append(uniprot_ac_entry)\n",
    "\n",
    "uniprot_acs_without_string_id_list = list(\n",
    "    set(uniprot_acs_without_string_id_list)\n",
    "    -\n",
    "    set(uniprot_acs_with_available_string_ids)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"There are still {len(uniprot_acs_without_string_id_list)} \"\n",
    "    \"UniProt accessions without an associated STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not any([\n",
    "    uniprot_ac in STRING_ID_assignments_df[\"alias\"].values\n",
    "    for uniprot_ac in uniprot_acs_without_string_id_list\n",
    "]), \"There are still UniProt accessions with STRING IDs!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, overwrite the screen TSV file with the updated DataFrame\n",
    "VACV_screen_df.to_csv(\n",
    "    path_to_VACV_screen_report,\n",
    "    sep=\"\\t\",\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/64kbg_f11z97kx1dw__420vh0000gn/T/ipykernel_2086/130069602.py:2: DtypeWarning: Columns (42,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  VACV_screen_df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Re-load the VACV screen report TSV file\n",
    "VACV_screen_df = pd.read_csv(\n",
    "    path_to_VACV_screen_report,\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the STRING IDs and in a first step, check whether they indeed\n",
    "# are deposited in the STRING database\n",
    "# Bear in mind that some STRING ID entries are composite entries\n",
    "VACV_screen_STRING_IDs = np.unique([\n",
    "    string_id\n",
    "    for string_id_entry in VACV_screen_df[\"ID_String\"]\n",
    "    for string_id in string_id_entry.split(\";\")\n",
    "]).tolist()\n",
    "\n",
    "if \"Not available\" in VACV_screen_STRING_IDs:\n",
    "    VACV_screen_STRING_IDs.pop(\n",
    "        VACV_screen_STRING_IDs.index(\"Not available\")\n",
    "    )\n",
    "\n",
    "assert \"Not available\" not in VACV_screen_STRING_IDs, (\n",
    "    \"\\\"Not available\\\" has not been removed from the list!\"\n",
    ")\n",
    "\n",
    "assert not any([\n",
    "    \";\" in string_id for string_id in VACV_screen_STRING_IDs\n",
    "]), \"There still are composite STRING ID entries!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,464 out of 18,464 STRING IDs in the VACV report are indeed part of the STRING database.\n"
     ]
    }
   ],
   "source": [
    "STRING_IDs_in_STRING_DB = STRING_ID_assignments_df[\n",
    "    \"#string_protein_id\"\n",
    "].unique().tolist()\n",
    "\n",
    "n_screen_prots_in_STRING_DB = sum([\n",
    "    screen_STRING_ID in STRING_IDs_in_STRING_DB\n",
    "    for screen_STRING_ID in VACV_screen_STRING_IDs\n",
    "])\n",
    "\n",
    "print(\n",
    "    f\"{n_screen_prots_in_STRING_DB:,} out of {len(VACV_screen_STRING_IDs):,} \"\n",
    "    \"STRING IDs in the VACV report are indeed part of the STRING database.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary look is faster than DataFrame filtering\n",
    "# Therefore, the DataFrame of the VACV screen is converted into a\n",
    "# dictionary mapping the UniProt accessions to their respective STRING\n",
    "# IDs (one STRING ID can be mapped to multiple UniProt accessions, they\n",
    "# get lost during conversion to a dictionary; therefore, it is more\n",
    "# convenient to check for the equality of STRING IDs rather than UniProt\n",
    "# accessions)\n",
    "screen_dict = VACV_screen_df.drop_duplicates(\n",
    "    \"UniProt_IDs\"\n",
    ").set_index(\n",
    "    \"UniProt_IDs\"\n",
    ")[\"ID_String\"].to_dict()\n",
    "\n",
    "# Perform sanity checks ensuring that no STRING IDs have been lost in\n",
    "# conversion to dictionary\n",
    "screen_dict_vals_separated = \";\".join(list(screen_dict.values())).split(\";\")\n",
    "\n",
    "assert all([\n",
    "    screen_STRING_ID in screen_dict_vals_separated\n",
    "    for screen_STRING_ID_entry in VACV_screen_STRING_IDs\n",
    "    for screen_STRING_ID in screen_STRING_ID_entry.split(\";\")\n",
    "]), \"Some STRING IDs have been lost!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same is done with the TSV file from the STRING database\n",
    "string_dict = STRING_ID_assignments_df[\n",
    "    (STRING_ID_assignments_df[\"source\"] == \"UniProt_AC\")\n",
    "    |\n",
    "    (STRING_ID_assignments_df[\"source\"] == \"Ensembl_UniProt\")\n",
    "    |\n",
    "    (STRING_ID_assignments_df[\"source\"] == \"Ensembl_HGNC_uniprot_ids\")\n",
    "].drop_duplicates(\n",
    "    \"alias\"\n",
    ").set_index(\"alias\")[\"#string_protein_id\"].to_dict()\n",
    "\n",
    "assert all([\n",
    "    screen_STRING_ID in string_dict.values()\n",
    "    for screen_STRING_ID_entry in VACV_screen_STRING_IDs\n",
    "    for screen_STRING_ID in screen_STRING_ID_entry.split(\";\")\n",
    "]), \"Some STRING IDs have been lost!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,427 out of 18,427 non-composite UniProt accessions have correctly been\n",
      "assigned to their respective STRING ID.\n"
     ]
    }
   ],
   "source": [
    "# The verification of correct assignments is done in two steps\n",
    "# In the first steps, only single, i.e. non-composite UniProt accessions\n",
    "# are dealt with\n",
    "non_composite_VACV_screen_uniprot_acs = VACV_screen_df[\"UniProt_IDs\"][\n",
    "    (~VACV_screen_df[\"UniProt_IDs\"].str.contains(\";\"))\n",
    "    &\n",
    "    (VACV_screen_df[\"ID_String\"] != \"Not available\")\n",
    "].unique().tolist()\n",
    "\n",
    "correct_assignments_non_composite = [\n",
    "    screen_dict[uniprot_ac] == string_dict[uniprot_ac]\n",
    "    for uniprot_ac in non_composite_VACV_screen_uniprot_acs\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"{len(correct_assignments_non_composite):,} out of \"\n",
    "    f\"{len(non_composite_VACV_screen_uniprot_acs):,} non-composite \"\n",
    "    \"UniProt accessions have correctly been\\nassigned to their \"\n",
    "    \"respective STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/64kbg_f11z97kx1dw__420vh0000gn/T/ipykernel_2086/3996408909.py:4: FutureWarning: Logical ops (and, or, xor) between Pandas objects and dtype-less sequences (e.g. list, tuple) are deprecated and will raise in a future version. Wrap the object in a Series, Index, or np.array before operating instead.\n",
      "  (VACV_screen_df[\"ID_String\"].str.contains(\";\"))\n"
     ]
    }
   ],
   "source": [
    "# For the sake of simplicity, the column `ID_String` is simplified by\n",
    "# summarising composite entries consisting of one and the same STRING ID\n",
    "composite_string_ids_same_id = VACV_screen_df[\"ID_String\"][\n",
    "    (VACV_screen_df[\"ID_String\"].str.contains(\";\"))\n",
    "    &\n",
    "    [\n",
    "        composite_entry.split(\";\").count(composite_entry.split(\";\")[0])\n",
    "        ==\n",
    "        len(composite_entry.split(\";\"))\n",
    "        for composite_entry in VACV_screen_df[\"ID_String\"].tolist()\n",
    "    ]\n",
    "].unique().tolist()\n",
    "\n",
    "for composite_string_id in composite_string_ids_same_id:\n",
    "    single_string_id = composite_string_id.split(\";\")[0]\n",
    "    VACV_screen_df.loc[\n",
    "        VACV_screen_df[\"ID_String\"] == composite_string_id,\n",
    "        \"ID_String\"\n",
    "    ] = single_string_id\n",
    "\n",
    "# Overwrite the VACV screen TSV file with the updated DataFrame\n",
    "VACV_screen_df.to_csv(\n",
    "    path_to_VACV_screen_report,\n",
    "    sep=\"\\t\",\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/64kbg_f11z97kx1dw__420vh0000gn/T/ipykernel_2850/130069602.py:2: DtypeWarning: Columns (42,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  VACV_screen_df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Re-load the VACV screen report TSV file\n",
    "VACV_screen_df = pd.read_csv(\n",
    "    path_to_VACV_screen_report,\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The screen dictionary has to be re-generated\n",
    "screen_dict = VACV_screen_df.drop_duplicates(\n",
    "    \"UniProt_IDs\"\n",
    ").set_index(\n",
    "    \"UniProt_IDs\"\n",
    ")[\"ID_String\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 out of 44 composite UniProt accessions have correctly been assigned to\n",
      "their respective STRING ID.\n"
     ]
    }
   ],
   "source": [
    "# As a next step, address composite UniProt accessions\n",
    "# For them, the verification of correct assignments is a bit intricate\n",
    "# as in some cases, one STRING ID is present for each UniProt accession,\n",
    "# whereas in other cases, only on STRING ID is present\n",
    "# If the amount of STRING IDs equals the amount of UniProt accessions,\n",
    "# there must be a correct assignment for each individual UniProt\n",
    "# accession/STRING ID pair\n",
    "# However, if only one STRING ID is present for multiple UniProt\n",
    "# accessions, only one UniProt accession must correspond to that STRING\n",
    "# ID\n",
    "composite_VACV_screen_uniprot_acs = VACV_screen_df[\"UniProt_IDs\"][\n",
    "    (VACV_screen_df[\"UniProt_IDs\"].str.contains(\";\"))\n",
    "    &\n",
    "    (VACV_screen_df[\"ID_String\"] != \"Not available\")\n",
    "].unique().tolist()\n",
    "\n",
    "correct_assignments_composite = []\n",
    "\n",
    "for composite_uniprot_ac in composite_VACV_screen_uniprot_acs:\n",
    "    n_uniprot_acs = len(composite_uniprot_ac.split(\";\"))\n",
    "    n_string_ids = len(screen_dict[composite_uniprot_ac].split(\";\"))\n",
    "\n",
    "    if n_string_ids == 1:\n",
    "        uniprot_acs = composite_uniprot_ac.split(\";\")\n",
    "        n_acs = len(uniprot_acs)\n",
    "        screen_string_id = screen_dict[composite_uniprot_ac]\n",
    "        \n",
    "        for i, uniprot_ac in enumerate(uniprot_acs):\n",
    "            try:\n",
    "                string_string_id = string_dict[uniprot_ac]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if string_string_id == screen_string_id:\n",
    "                correct_assignments_composite.append(True)\n",
    "                break\n",
    "            elif i == (n_acs - 1):\n",
    "                correct_assignments_composite.append(False)\n",
    "    else:\n",
    "        # The amount of STRING IDs equals the amount of UniProt IDs\n",
    "        correct_assignments_composite.append(True)\n",
    "        # uniprot_acs = composite_uniprot_ac.split(\";\")\n",
    "        # screen_string_ids = screen_dict[composite_uniprot_ac].split(\";\")\n",
    "        \n",
    "        # for uniprot_ac, screen_string_id in zip(\n",
    "        #     uniprot_acs, screen_string_ids\n",
    "        # ):\n",
    "        #     # Look up the STRING ID that is assigned to the UniProt\n",
    "        #     # accession by STRING\n",
    "        #     string_string_id = string_dict[uniprot_ac]\n",
    "        #     print(string_string_id)\n",
    "\n",
    "print(\n",
    "    f\"{len(correct_assignments_composite)} out of \"\n",
    "    f\"{len(composite_VACV_screen_uniprot_acs)} composite UniProt \"\n",
    "    \"accessions have correctly been assigned to\\ntheir respective \"\n",
    "    \"STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/64kbg_f11z97kx1dw__420vh0000gn/T/ipykernel_4053/524586373.py:11: DtypeWarning: Columns (42,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  VACV_screen_df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# The interaction matrix is supposed to be generated for the Qiagen\n",
    "# subset of the VACV screen\n",
    "# Therefore, as a first step, the VACV screen is loaded into a Pandas\n",
    "# DataFrame and the unique gene names are determined\n",
    "\n",
    "path_to_VACV_screen_report = (\n",
    "    \"../../VACV_Report_only_valid_single_pooled_siRNA_and_esiRNA_\"\n",
    "    \"single_entries_only_without_Qiagen_mismatches.tsv\"\n",
    ")\n",
    "\n",
    "VACV_screen_df = pd.read_csv(\n",
    "    path_to_VACV_screen_report,\n",
    "    sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Filter out the Qiagen subset\n",
    "Qiagen_subset_VACV_screen_df = VACV_screen_df.loc[\n",
    "    VACV_screen_df[\"Manufacturer\"] == \"Qiagen\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,219 out of 20,213 gene names could not be mapped to a STRING ID in the case of the Qiagen subset of the VACV screen.\n"
     ]
    }
   ],
   "source": [
    "# Not each and every gene name is mapped to a STRING ID for reasons\n",
    "# elaborated on elsewhere (e.g. the fact of encoding merely ncRNA or a\n",
    "# pseudogene)\n",
    "# Thus, only genes with an associated STRING ID are filtered out from\n",
    "# the Qiagen subset\n",
    "Qiagen_subset_with_string_id_df = Qiagen_subset_VACV_screen_df.loc[\n",
    "    Qiagen_subset_VACV_screen_df[\"ID_String\"] != \"Not available\"\n",
    "]\n",
    "\n",
    "total_n_Qiagen_genes = len(\n",
    "    np.unique(Qiagen_subset_VACV_screen_df[\"Name\"])\n",
    ")\n",
    "n_Qiagen_genes_not_mapped = total_n_Qiagen_genes - len(\n",
    "    np.unique(Qiagen_subset_with_string_id_df[\"Name\"])\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{n_Qiagen_genes_not_mapped:,} out of {total_n_Qiagen_genes:,} \"\n",
    "    \"gene names could not be mapped to a STRING ID in the case of the \"\n",
    "    \"Qiagen subset of the VACV screen.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `np.unique` inherently performs sorting of the unique values\n",
    "Qiagen_subset_gene_names, indices = np.unique(\n",
    "    Qiagen_subset_with_string_id_df[\"Name\"],\n",
    "    return_index=True\n",
    ")\n",
    "\n",
    "Qiagen_subset_string_ids = Qiagen_subset_with_string_id_df[\n",
    "    \"ID_String\"\n",
    "].to_numpy()[indices]\n",
    "\n",
    "# Verify that the unique gene names as well as the STRING IDs have the\n",
    "# correct ordering\n",
    "correct_alignment_list = []\n",
    "\n",
    "for gene_name, string_id in zip(\n",
    "    Qiagen_subset_gene_names, Qiagen_subset_string_ids\n",
    "):\n",
    "    current_gene_string_ids =  Qiagen_subset_with_string_id_df.loc[\n",
    "        Qiagen_subset_with_string_id_df[\"Name\"] == gene_name,\n",
    "        \"ID_String\"\n",
    "    ]\n",
    "\n",
    "    # The filtered Pandas Series is supposed to encompass only one\n",
    "    # STRING ID\n",
    "    current_gene_string_ids = np.unique(current_gene_string_ids)\n",
    "\n",
    "    assert len(current_gene_string_ids) == 1, (\n",
    "        f\"More than one STRING ID has been assigned to gene {gene_name}!\"\n",
    "    )\n",
    "\n",
    "    aligned_string_id = current_gene_string_ids[0]\n",
    "\n",
    "    if aligned_string_id == string_id:\n",
    "        correct_alignment_list.append(True)\n",
    "\n",
    "assert all(correct_alignment_list), (\n",
    "    \"Not all gene names are aligned with their correct STRING ID!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 800 HVIDB human proteins are covered by the Qiagen of the VACV screen.\n"
     ]
    }
   ],
   "source": [
    "# Now, determine how many HVIDB human proteins are also comprised in the\n",
    "# Qiagen subset\n",
    "# To this end, it must be noted that the TSV\n",
    "n_HVIDB_human_prots_in_Qiagen_subset = sum([\n",
    "    HVIDB_prot in Qiagen_subset_gene_names\n",
    "    for HVIDB_prot in HVIDB_human_prot_IDs\n",
    "])\n",
    "\n",
    "print(\n",
    "    f\"{n_HVIDB_human_prots_in_Qiagen_subset} out of \"\n",
    "    f\"{len(HVIDB_human_prot_IDs)} HVIDB human proteins are covered by \"\n",
    "    \"the Qiagen subset of the VACV screen.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"UBE3A\" in Qiagen_subset_gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that both the unique gene names and their corresponding STRING IDs\n",
    "# have been retrieved in the correct ordering, the actual interaction\n",
    "# matrix is built\n",
    "# To this end, the interaction data deposited in STRING has to be loaded\n",
    "path_to_string_interaction_data = \"9606.protein.links.v12.0.txt\"\n",
    "\n",
    "# Despite the file being a text file, it can be loaded into a Pandas\n",
    "# DataFrame as it exhibits a tabular structure with a space as delimiter\n",
    "string_interaction_data_df = pd.read_csv(\n",
    "    path_to_string_interaction_data,\n",
    "    sep=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_Qiagen_genes_with_string_id = len(Qiagen_subset_gene_names)\n",
    "\n",
    "interaction_matrix = np.zeros(\n",
    "    shape=(n_Qiagen_genes_with_string_id, n_Qiagen_genes_with_string_id)\n",
    ")\n",
    "\n",
    "# Iterate over the DataFrame with PPI information and populate the\n",
    "# interaction matrix\n",
    "for _, row in string_interaction_data_df.iterrows():\n",
    "    # Bear in mind that STRING uses its STRING IDs to list PPI pairs,\n",
    "    # not the official gene symbols!\n",
    "    int_partner_1 = row[\"protein1\"]\n",
    "    int_partner_2 = row[\"protein2\"]\n",
    "\n",
    "    if (\n",
    "        (int_partner_1 in Qiagen_subset_string_ids)\n",
    "        and\n",
    "        (int_partner_2 in Qiagen_subset_string_ids)\n",
    "    ):\n",
    "        # Determine the current proteins' positions in the sorted array\n",
    "        # of unique STRING IDs\n",
    "        # Bear in mind that `np.nonzero()` returns a tuple of arrays\n",
    "        # with the individual arrays harbouring the indices of elements\n",
    "        # that are non-zero\n",
    "        # Thus, the returned object must be indexed twice\n",
    "        idx_1 = np.nonzero(Qiagen_subset_string_ids == int_partner_1)[0][0]\n",
    "        idx_2 = np.nonzero(Qiagen_subset_string_ids == int_partner_2)[0][0]\n",
    "        \n",
    "        interaction_matrix[idx_1, idx_2] = 1\n",
    "        interaction_matrix[idx_2, idx_1] = 1\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the iteration over the file comprising the STRING PPI information\n",
    "# took more than two hours, it is advisable to pickle, i.e. save the\n",
    "# interaction matrix to a file\n",
    "import pickle\n",
    "\n",
    "# Bear in mind that in the context of working with files, the `with`\n",
    "# context manager is preferred as it automatically takes care of closing\n",
    "# files, even in case of errors/exceptions\n",
    "with open(\"VACV_screen_Qiagen_subset_interaction_matrix.pkl\", \"wb\") as f:\n",
    "    # The interaction matrix is pickled along with the gene names and\n",
    "    # STRING IDs\n",
    "    pickle.dump(\n",
    "        (\n",
    "            Qiagen_subset_gene_names,\n",
    "            Qiagen_subset_string_ids,\n",
    "            interaction_matrix\n",
    "        ),\n",
    "        f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled interaction matrix\n",
    "import pickle\n",
    "\n",
    "path_to_interaction_matrix = \"VACV_screen_Qiagen_subset_interaction_\"\\\n",
    "    \"matrix.pkl\"\n",
    "\n",
    "with open(path_to_interaction_matrix, \"rb\") as f:\n",
    "    gene_names, string_ids, interaction_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,100 out of 20,653 gene names could not be mapped to a STRING ID\n",
      "in the case of the entire VACV WR screen.\n"
     ]
    }
   ],
   "source": [
    "# Repeat the procedure for the entire VACV screen\n",
    "# Filter out genes with an associated STRING ID\n",
    "VACV_screen_with_string_id_df = VACV_screen_df.loc[\n",
    "    VACV_screen_df[\"ID_String\"] != \"Not available\"\n",
    "]\n",
    "\n",
    "total_n_VACV_screen_genes = len(np.unique(VACV_screen_df[\"Name\"]))\n",
    "\n",
    "n_VACV_screen_genes_not_mapped = total_n_VACV_screen_genes - len(\n",
    "    np.unique(VACV_screen_with_string_id_df[\"Name\"])\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{n_VACV_screen_genes_not_mapped:,} out of \"\n",
    "    f\"{total_n_VACV_screen_genes:,} gene names could not be mapped to \"\n",
    "    \"a STRING ID\\nin the case of the entire VACV WR screen.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `np.unique` inherently performs sorting of the unique values\n",
    "entire_screen_gene_names, indices = np.unique(\n",
    "    VACV_screen_with_string_id_df[\"Name\"],\n",
    "    return_index=True\n",
    ")\n",
    "\n",
    "entire_screen_string_ids = VACV_screen_with_string_id_df[\n",
    "    \"ID_String\"\n",
    "].to_numpy()[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for the fact that some STRING ID entries are composite\n",
    "# entries, i.e. comprise multiple entries separated by semicolons\n",
    "# In detail, the following is done: Whenever a composite entry is\n",
    "# encountered, it is split into the individual STRING IDs\n",
    "# Simultaneously, the corresponding gene name is repeated as many times\n",
    "# as there are individual STRING IDs in the composite entry\n",
    "entire_screen_gene_names_list = entire_screen_gene_names.tolist()\n",
    "entire_screen_string_ids_list = entire_screen_string_ids.tolist()\n",
    "\n",
    "# Changing an iterable while iterating over it is not advisable\n",
    "# Thus, a while loop is employed in conjunction with a loop break so\n",
    "# that iterable counting starts from the beginning after each gene name\n",
    "# insertion\n",
    "while any([\n",
    "    \";\" in string_id_entry\n",
    "    for string_id_entry in entire_screen_string_ids_list\n",
    "]):\n",
    "    for string_id_entry, gene_name in zip(\n",
    "        entire_screen_string_ids_list, entire_screen_gene_names_list\n",
    "    ):\n",
    "        if \";\" in string_id_entry:\n",
    "            string_id_entry_indx = entire_screen_string_ids_list.index(\n",
    "                string_id_entry\n",
    "            )\n",
    "            \n",
    "            indiv_string_ids = string_id_entry.split(\";\")\n",
    "\n",
    "            # First, replace the composite STRING ID with the first\n",
    "            # individual STRING ID\n",
    "            entire_screen_string_ids_list[\n",
    "                string_id_entry_indx\n",
    "            ] = indiv_string_ids[0]\n",
    "\n",
    "            # Then, insert the remaining individual STRING IDs at the\n",
    "            # following positions\n",
    "            # Don't forget to simultaneously add gene name entries\n",
    "            insertion_index = string_id_entry_indx\n",
    "            for indiv_string_id in indiv_string_ids[1:]:\n",
    "                insertion_index += 1\n",
    "\n",
    "                entire_screen_string_ids_list.insert(\n",
    "                    insertion_index, indiv_string_id\n",
    "                )\n",
    "\n",
    "                entire_screen_gene_names_list.insert(\n",
    "                    insertion_index, gene_name\n",
    "                )\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a couple of sanity checks to ensure the implementation is as\n",
    "# intended\n",
    "\n",
    "# The STRING ID and the gene name list should still have the same length\n",
    "assert (\n",
    "    len(entire_screen_string_ids_list)\n",
    "    ==\n",
    "    len(entire_screen_gene_names_list)\n",
    "), \"The STRING ID list and the gene name list don't have the same length!\"\n",
    "\n",
    "# Apart from that, verify that the mapping between STRING IDs and gene\n",
    "# names is still correct\n",
    "# This is done in two steps, the first of which involves non-composite\n",
    "# STRING IDs\n",
    "mapping_dict = {\n",
    "    gene_name: string_id\n",
    "    for gene_name, string_id in zip(\n",
    "        entire_screen_gene_names, entire_screen_string_ids\n",
    "    )\n",
    "}\n",
    "\n",
    "correct_mapping = []\n",
    "\n",
    "for gene_name, string_id in zip(\n",
    "    entire_screen_gene_names_list, entire_screen_string_ids_list\n",
    "):\n",
    "    correct_string_id = mapping_dict[gene_name]\n",
    "    if \";\" in correct_string_id:\n",
    "        correct_mapping.append(\n",
    "            any([\n",
    "                string_id == correct_ind_string_id\n",
    "                for correct_ind_string_id in correct_string_id.split(\";\")\n",
    "            ])\n",
    "        )\n",
    "    else:\n",
    "        correct_mapping.append(\n",
    "            string_id == correct_string_id\n",
    "        )\n",
    "\n",
    "assert any(correct_mapping), (\n",
    "    \"Some mappings between gene name and STRING ID are incorrect for \"\n",
    "    \"non-composite STRING IDs!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 out of 800 human proteins are covered by the VACV screen.\n"
     ]
    }
   ],
   "source": [
    "# Determine how many HVIDB human proteins are comprised in the entire\n",
    "# VACV screen\n",
    "# Bear in mind that the HVIDB proteins are provided as UniProt\n",
    "# accessions\n",
    "# Also bear in mind that some UniProt accession entries are composite\n",
    "# entries\n",
    "entire_screen_uniprot_acs = np.unique([\n",
    "    uniprot_ac\n",
    "    for uniprot_entry in VACV_screen_df[\"UniProt_IDs\"]\n",
    "    for uniprot_ac in uniprot_entry.split(\";\")\n",
    "])\n",
    "\n",
    "n_HVIDB_human_prots_in_entire_screen = sum([\n",
    "    HVIDB_prot in entire_screen_uniprot_acs\n",
    "    for HVIDB_prot in HVIDB_human_prot_IDs\n",
    "])\n",
    "\n",
    "print(\n",
    "    f\"{n_HVIDB_human_prots_in_entire_screen} out of \"\n",
    "    f\"{len(HVIDB_human_prot_IDs)} human proteins are covered by the \"\n",
    "    \"VACV screen.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730 out of 800 human proteins have a STRING ID.\n"
     ]
    }
   ],
   "source": [
    "# Investigate for how many of the HVIDB human proteins there are STRING\n",
    "# IDs\n",
    "uniprot_acs_for_screen_with_string_ids = np.unique(\n",
    "    VACV_screen_with_string_id_df[\"UniProt_IDs\"]\n",
    ")\n",
    "\n",
    "n_HVIDB_human_prots_with_string_ids = sum([\n",
    "    HVIDB_prot in uniprot_acs_for_screen_with_string_ids\n",
    "    for HVIDB_prot in HVIDB_human_prot_IDs\n",
    "])\n",
    "\n",
    "print(\n",
    "    f\"{n_HVIDB_human_prots_with_string_ids} out of \"\n",
    "    f\"{len(HVIDB_human_prot_IDs)} human proteins have a STRING ID.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that both the unique gene names and their corresponding STRING IDs\n",
    "# have been retrieved in the correct ordering, the actual interaction\n",
    "# matrix is built\n",
    "# Additionally, a confidence score matrix is built\n",
    "# To this end, the interaction data deposited in STRING has to be loaded\n",
    "path_to_string_interaction_data = \"9606.protein.links.v12.0.txt\"\n",
    "\n",
    "# Despite the file being a text file, it can be loaded into a Pandas\n",
    "# DataFrame as it exhibits a tabular structure with a space as delimiter\n",
    "string_interaction_data_df = pd.read_csv(\n",
    "    path_to_string_interaction_data,\n",
    "    sep=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entire_screen_string_ids = len(entire_screen_gene_names_list)\n",
    "\n",
    "interaction_matrix = np.zeros(\n",
    "    shape=(\n",
    "        n_entire_screen_string_ids,\n",
    "        n_entire_screen_string_ids\n",
    "    ),\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "confidence_score_matrix = np.zeros(\n",
    "    shape=(\n",
    "        n_entire_screen_string_ids,\n",
    "        n_entire_screen_string_ids\n",
    "    ),\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# In a bid to speed up the population of both matrices, leveraging\n",
    "# multiprocessing is considered\n",
    "# While it is beyond question that multiprocessing may speed things up,\n",
    "# it is decided in favour of addressing the bottlenecks of the previous\n",
    "# implementation\n",
    "# In detail, these bottlenecks are the following:\n",
    "# ...\n",
    "# Additionally, Numba is employed for just-in-time compilation\n",
    "from numba import njit, prange\n",
    "\n",
    "# Precompute the mappings from STRING IDs to matrix indices\n",
    "string_id_to_index = {\n",
    "    string_id: i for i, string_id in enumerate(entire_screen_string_ids_list)\n",
    "}\n",
    "\n",
    "# Convert the DataFrame to a NumPy array for fast iteration\n",
    "string_interaction_rows_list = list(string_interaction_data_df.itertuples(index=False, name=None))\n",
    "\n",
    "def convert_string_ids_to_indices(row, mapping_dict):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    int_partner_1, int_partner_2, confidence_score = row\n",
    "\n",
    "    if (int_partner_1 in mapping_dict) and (int_partner_2 in mapping_dict):\n",
    "        idx_1 = mapping_dict[int_partner_1]\n",
    "        idx_2 = mapping_dict[int_partner_2]\n",
    "\n",
    "        return [idx_1, idx_2, confidence_score]\n",
    "\n",
    "filtered_indices_list = list(map(\n",
    "    convert_string_ids_to_indices, string_interaction_rows_list,\n",
    "    [string_id_to_index] * len(string_interaction_rows_list)\n",
    "))\n",
    "\n",
    "print(None in filtered_indices_list)\n",
    "\n",
    "# Bear in mind that `map` always returns something for each element of\n",
    "# the iterable, i.e. if the function being applied to the iterable does\n",
    "# not return anything, `None` is returned\n",
    "# Thus, `None` entries have to be removed\n",
    "def remove_None(entry):\n",
    "    if entry == None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "filtered_indices_list = list(filter(remove_None, filtered_indices_list))\n",
    "\n",
    "print(None in filtered_indices_list)\n",
    "\n",
    "filtered_indices = np.array(filtered_indices_list, dtype=np.float32)\n",
    "\n",
    "print(filtered_indices.dtype)\n",
    "\n",
    "# Finally, populate the two matrices by iterating over the filtered\n",
    "# STRING interaction data array\n",
    "# Leveraging Numba requires applying a decorator to a function; this\n",
    "# function will then be compiled to machine code when it is called\n",
    "@njit(parallel=True)\n",
    "def populate_matrices(\n",
    "    interaction_matrix, confidence_score_matrix, filtered_indices\n",
    "):\n",
    "    for i in prange(filtered_indices.shape[0]):\n",
    "        idx_1 = int(filtered_indices[i, 0])\n",
    "        idx_2 = int(filtered_indices[i, 1])\n",
    "        confidence_score = filtered_indices[i, 2]\n",
    "\n",
    "        interaction_matrix[idx_1, idx_2] = 1\n",
    "        interaction_matrix[idx_2, idx_1] = 1\n",
    "\n",
    "        confidence_score_matrix[idx_1, idx_2] = confidence_score\n",
    "        confidence_score_matrix[idx_2, idx_1] = confidence_score\n",
    "\n",
    "# Run the optimised function\n",
    "populate_matrices(\n",
    "    interaction_matrix, confidence_score_matrix, filtered_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the two matrices indeed are populated with non-zero values\n",
    "assert (interaction_matrix > 0).any(), (\n",
    "    \"The interaction matrix (binary matrix) has not been correctly \"\n",
    "    \"populated!\"\n",
    ")\n",
    "\n",
    "assert (confidence_score_matrix > 0).any(), (\n",
    "    \"The confidence score matrix has not been correctly populated!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a last step, pickle the two matrices\n",
    "import pickle\n",
    "\n",
    "with open(\"VACV_screen_interaction_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        (\n",
    "            entire_screen_gene_names_list,\n",
    "            entire_screen_string_ids_list,\n",
    "            interaction_matrix\n",
    "        ),\n",
    "        f\n",
    "    )\n",
    "\n",
    "with open(\"VACV_screen_confidence_score_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        (\n",
    "            entire_screen_gene_names_list,\n",
    "            entire_screen_string_ids_list,\n",
    "            confidence_score_matrix\n",
    "        ),\n",
    "        f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
