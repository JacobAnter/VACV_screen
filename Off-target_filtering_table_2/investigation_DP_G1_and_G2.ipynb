{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a21e799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe purpose of this Jupyter notebook is to investigate the controls\\ncomprised in the subsets \"Dharmacon pooled Genome 1\" (\"Experiment\" value\\n\"VACCINIA-GP-G1\") and \"Dharmacon pooled Genome 2\" (\"Experiment\" value\\n\"VACCINIA-GP-G2\").\\n\\nTo be more precise, it is checked which controls are present in the\\nindividual assay plates (note the distinction between chequerboard\\nplates and assay plates/screening plates: the former are characterised\\nby the fact of exclusively containing controls, whereas the latter\\nharbour both controls and siRNA interrogations).\\n\\nSubsequently, the variability of the controls across the individual\\nplates is determined in two ways: The first way involves using the raw\\nintensity values. For each plate, control and column, the mean intensity\\nas well as the standard deviation are computed. Based on ...\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The purpose of this Jupyter notebook is to investigate the controls\n",
    "comprised in the subsets \"Dharmacon pooled Genome 1\" (\"Experiment\" value\n",
    "\"VACCINIA-GP-G1\") and \"Dharmacon pooled Genome 2\" (\"Experiment\" value\n",
    "\"VACCINIA-GP-G2\").\n",
    "\n",
    "To be more precise, it is checked which controls are present in the\n",
    "individual assay plates (note the distinction between chequerboard\n",
    "plates and assay plates/screening plates: the former are characterised\n",
    "by the fact of exclusively containing controls, whereas the latter\n",
    "harbour both controls and siRNA interrogations).\n",
    "\n",
    "Subsequently, the variability of the controls across the individual\n",
    "plates is determined in two ways: The first way involves using the raw\n",
    "intensity values. For each plate, control and column, the mean intensity\n",
    "as well as the standard deviation are computed. Based on ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc7064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6be0aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/64kbg_f11z97kx1dw__420vh0000gn/T/ipykernel_1813/2894677132.py:6: DtypeWarning: Columns (37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  VACV_report_df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "path_to_VACV_report = (\n",
    "    \"/Users/jacobanter/Documents/Code/VACV_screen/VacciniaReport_\"\n",
    "    \"20170223-0958_ZScored_conc_and_NaN_adjusted.csv\"\n",
    ")\n",
    "\n",
    "VACV_report_df = pd.read_csv(\n",
    "    path_to_VACV_report,\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998493ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the two Dharmacon pooled subsets (note that DP-G1 and DP-G2\n",
    "# represent technical replicates/duplicates, i.e. DP-G1 and DP-G2\n",
    "# represent the first and second experiment, respectively)\n",
    "# Only screening plates are supposed to be considered\n",
    "DP_G1_df = VACV_report_df[\n",
    "    (VACV_report_df[\"Experiment\"] == \"VACCINIA-DP-G1\")\n",
    "    &\n",
    "    (VACV_report_df[\"PLATE_TYPE\"] == \"ScreeningPlate\")\n",
    "]\n",
    "\n",
    "DP_G2_df = VACV_report_df[\n",
    "    (VACV_report_df[\"Experiment\"] == \"VACCINIA-DP-G2\")\n",
    "    &\n",
    "    (VACV_report_df[\"PLATE_TYPE\"] == \"ScreeningPlate\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba0a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ScreeningPlate']\n",
      "['ScreeningPlate']\n"
     ]
    }
   ],
   "source": [
    "# Verify that these two subsets encompass exclusively screening plates\n",
    "print(np.unique(DP_G1_df[\"PLATE_TYPE\"]))\n",
    "print(np.unique(DP_G2_df[\"PLATE_TYPE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebe6a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of plates comprised in each subset:\n",
      "DP-G1: 57\n",
      "DP-G2: 57\n"
     ]
    }
   ],
   "source": [
    "# Now, determine the individual plates comprised in each subset\n",
    "plates_DP_G1 = np.unique(DP_G1_df[\"Barcode\"])\n",
    "plates_DP_G2 = np.unique(DP_G2_df[\"Barcode\"])\n",
    "\n",
    "print(\n",
    "    \"Amount of plates comprised in each subset:\\n\"\n",
    "    f\"DP-G1: {len(plates_DP_G1)}\\n\"\n",
    "    f\"DP-G2: {len(plates_DP_G2)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bd28a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two replicates do not share any plates!\n"
     ]
    }
   ],
   "source": [
    "# As DP-G1 and DP-G2 represent technical replicates/duplicates, it is\n",
    "# conceivable that they encompass the same plates; this is checked\n",
    "# Set operations are utilised for this purpose\n",
    "plates_DP_G1_set = set(plates_DP_G1)\n",
    "plates_DP_G2_set = set(plates_DP_G2)\n",
    "\n",
    "plates_intersection = plates_DP_G1_set & plates_DP_G2_set\n",
    "\n",
    "if (\n",
    "    (len(plates_intersection) == len(plates_DP_G1))\n",
    "    and\n",
    "    (len(plates_intersection) == len(plates_DP_G2))\n",
    "):\n",
    "    print(\"The two replicates share the same plates!\")\n",
    "elif len(plates_intersection) > 0:\n",
    "    print(\n",
    "        \"The two replicates share some, but not all plates!\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"The two replicates do not share any plates!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d95d652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, determine the controls contained in each plate\n",
    "controls_per_plate_DP_G1 = []\n",
    "controls_per_plate_DP_G2 = []\n",
    "\n",
    "n_controls_per_plate_DP_G1 = []\n",
    "n_controls_per_plate_DP_G2 = []\n",
    "\n",
    "for plate_id_G1, plate_id_G2 in zip(plates_DP_G1, plates_DP_G2):\n",
    "    subset_G1_df = DP_G1_df[\n",
    "        (DP_G1_df[\"Barcode\"] == plate_id_G1)\n",
    "        &\n",
    "        (DP_G1_df[\"WellType\"] == \"CONTROL\")\n",
    "    ]\n",
    "\n",
    "    controls_per_plate_DP_G1.append(\n",
    "        np.unique(subset_G1_df[\"Name\"])\n",
    "    )\n",
    "\n",
    "    n_controls_G1 = len(np.unique(subset_G1_df[\"Name\"]))\n",
    "    n_controls_per_plate_DP_G1.append(n_controls_G1)\n",
    "\n",
    "    subset_G2_df = DP_G2_df[\n",
    "        (DP_G2_df[\"Barcode\"] == plate_id_G2)\n",
    "        &\n",
    "        (DP_G2_df[\"WellType\"] == \"CONTROL\")\n",
    "    ]\n",
    "\n",
    "    controls_per_plate_DP_G2.append(\n",
    "        np.unique(subset_G2_df[\"Name\"])\n",
    "    )\n",
    "\n",
    "    n_controls_G2 = len(np.unique(subset_G2_df[\"Name\"]))\n",
    "    n_controls_per_plate_DP_G2.append(n_controls_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebc1162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 12, 13, 13, 13, 12, 12, 13, 12, 12, 13, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13]\n",
      "[12, 12, 12, 13, 13, 13, 12, 12, 13, 12, 12, 13, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    np.array(n_controls_per_plate_DP_G1)\n",
    "    ==\n",
    "    np.array(n_controls_per_plate_DP_G2)\n",
    ").all(), (\n",
    "    \"The amounts of controls per plate do not match between the \"\n",
    "    \"duplicates!\"\n",
    ")\n",
    "\n",
    "print(n_controls_per_plate_DP_G1)\n",
    "print(n_controls_per_plate_DP_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3043504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to a numerical check, the precise identity of the controls\n",
    "# is also determined\n",
    "# Bear in mind that when comparisong two ragged arrays via `==`,\n",
    "# comparison of the arrays as a whole rather than element-wise\n",
    "# comparison is performed, returning a single boolean value instead of\n",
    "# the usual boolean array\n",
    "# Therefore, element-wise comparison has to be accomplished e.g. by\n",
    "# means of list comprehensions\n",
    "assert np.array([\n",
    "    element_G1 == element_G2\n",
    "    for plate_list_G1, plate_list_G2 in\n",
    "    zip(controls_per_plate_DP_G1, controls_per_plate_DP_G2)\n",
    "    for element_G1, element_G2 in zip(plate_list_G1, plate_list_G2)\n",
    "]).all(), (\n",
    "    \"The two replicates do not have all or no controls at all in \"\n",
    "    \"common!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f194378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"core controls\" encompass 12 controls.\n"
     ]
    }
   ],
   "source": [
    "# Astonishingly, there is a complete match regarding the controls for\n",
    "# each and every plate\n",
    "# The \"core controls\", i.e. controls shared by all plates are determined\n",
    "control_sets = [\n",
    "    set(control_per_plate) for control_per_plate in (\n",
    "        controls_per_plate_DP_G1 + controls_per_plate_DP_G2\n",
    "    )\n",
    "]\n",
    "\n",
    "assert len(control_sets) == (\n",
    "    len(controls_per_plate_DP_G1)\n",
    "    +\n",
    "    len(controls_per_plate_DP_G2)\n",
    "), \"Something went wrong during the generation of the sets!\"\n",
    "\n",
    "core_controls_set = set.intersection(*control_sets)\n",
    "\n",
    "print(\n",
    "    f\"The \\\"core controls\\\" encompass {len(core_controls_set)} controls.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea15fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precise identity of the \"core controls\" is as follows:\n",
      "RAC1\n",
      "ARPC3\n",
      "MOCK\n",
      "PSMC3\n",
      "PAK1\n",
      "SCRAMBLED\n",
      "CDC42\n",
      "ATP6V1A\n",
      "GFP Duplex III\n",
      "PSMA6\n",
      "TSG101\n",
      "KIF11\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The precise identity of the \\\"core controls\\\" is as follows:\"\n",
    ")\n",
    "\n",
    "for control in core_controls_set:\n",
    "    print(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7317e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the \"core controls\", the mean intensity as well as the\n",
    "# standard deviation are computed on a per-plate as well as on a\n",
    "# per-column basis\n",
    "# Also bear in mind that duplicates are available (Genome 1 and Genome\n",
    "# 2)\n",
    "# To this end, the columns containing the raw intensities are determined\n",
    "early_raw_int_cols = [\n",
    "    column for column in VACV_report_df.columns\n",
    "    if (\"dIntensity\" in column) and (\"Late\" not in column)\n",
    "    and (\"nZScore\" not in column)\n",
    "]\n",
    "late_raw_int_cols = [\n",
    "    column for column in VACV_report_df.columns\n",
    "    if (\"dIntensity\" in column) and (\"Late\" in column)\n",
    "    and (\"nZScore\" not in column)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129e7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame to populate with the computed values\n",
    "# The DataFrame is supposed to encompass the following information for\n",
    "# each control on a per-replicate, per-plate and per-column basis:\n",
    "# mean intensity and standard deviation\n",
    "# To this end, a MultiIndex is created\n",
    "indices = [\n",
    "    [\"DP-G1\"] * len(core_controls_set) * len(plates_DP_G1)\n",
    "    +\n",
    "    [\"DP-G2\"] * len(core_controls_set) * len(plates_DP_G2),\n",
    "    [\n",
    "        plate_id\n",
    "        for plate_id in plates_DP_G1\n",
    "        for _ in range(len(core_controls_set))\n",
    "    ]\n",
    "    +\n",
    "    [\n",
    "        plate_id\n",
    "        for plate_id in plates_DP_G2\n",
    "        for _ in range(len(core_controls_set))\n",
    "    ],\n",
    "    (list(core_controls_set) * len(plates_DP_G1)\n",
    "    +\n",
    "    list(core_controls_set) * len(plates_DP_G2))\n",
    "]\n",
    "\n",
    "# Verify that all sublists encompass the same amount of elements\n",
    "assert len(set(list(map(len, indices)))) == 1, (\n",
    "    \"The indices for the MultiIndex have not been constructed \"\n",
    "    \"correctly!\"\n",
    ")\n",
    "\n",
    "multi_index = pd.MultiIndex.from_arrays(\n",
    "    indices,\n",
    "    names=[\"Replicate\", \"Plate_ID\", \"Control_name\"]\n",
    ")\n",
    "\n",
    "df_col_names = [\n",
    "    \"_\".join([col_name, suffix])\n",
    "    for col_name in (early_raw_int_cols + late_raw_int_cols)\n",
    "    for suffix in [\"mean\", \"std\"]\n",
    "]\n",
    "\n",
    "raw_control_vals_df = pd.DataFrame(\n",
    "    columns=df_col_names,\n",
    "    index=multi_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208c0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for core_control in core_controls_set:\n",
    "    for plate_id in plates_DP_G1:\n",
    "        for i, col_name in enumerate(early_raw_int_cols + late_raw_int_cols):\n",
    "            current_subset = DP_G1_df.loc[\n",
    "                (DP_G1_df[\"Barcode\"] == plate_id)\n",
    "                &\n",
    "                (DP_G1_df[\"Name\"] == core_control),\n",
    "                col_name\n",
    "            ]\n",
    "\n",
    "            current_mean = np.nanmean(current_subset)\n",
    "            current_std = np.nanstd(current_subset)\n",
    "\n",
    "            raw_control_vals_df.loc[\n",
    "                (\"DP-G1\", plate_id, core_control),\n",
    "                df_col_names[2 * i]\n",
    "            ] = current_mean\n",
    "            raw_control_vals_df.loc[\n",
    "                (\"DP-G1\", plate_id, core_control),\n",
    "                df_col_names[2 * i + 1]\n",
    "            ] = current_std\n",
    "\n",
    "    for plate_id in plates_DP_G2:\n",
    "        for i, col_name in enumerate(early_raw_int_cols + late_raw_int_cols):\n",
    "            current_subset = DP_G2_df.loc[\n",
    "                (DP_G2_df[\"Barcode\"] == plate_id)\n",
    "                &\n",
    "                (DP_G2_df[\"Name\"] == core_control),\n",
    "                col_name\n",
    "            ]\n",
    "\n",
    "            current_mean = np.nanmean(current_subset)\n",
    "            current_std = np.nanstd(current_subset)\n",
    "\n",
    "            raw_control_vals_df.loc[\n",
    "                (\"DP-G2\", plate_id, core_control),\n",
    "                df_col_names[2 * i]\n",
    "            ] = current_mean\n",
    "            raw_control_vals_df.loc[\n",
    "                (\"DP-G2\", plate_id, core_control),\n",
    "                df_col_names[2 * i + 1]\n",
    "            ] = current_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae12838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the DataFrame does not contain any `NaN` values\n",
    "assert np.count_nonzero(\n",
    "    np.isnan(raw_control_vals_df.to_numpy(dtype=np.float64))\n",
    ") == 0, (\n",
    "    \"The DataFrame contains `NaN` entries!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01e7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_control_vals_df.to_csv(\n",
    "    \"mean_and_std_of_intensity_per_col_DP-G1_and_DP-G2_raw_vals.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=True,\n",
    "    index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a4cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the variability, i.e. the standard deviation across the plates\n",
    "# for each control\n",
    "# Additionally, the mean of the mean intensities across all plates is\n",
    "# computed for each control\n",
    "# Both the mean and the variability are computed for each control on a\n",
    "# per-column basis\n",
    "# Again, the results are kept track of in a DataFrame\n",
    "# While the columns of the DataFrame are the different early and late\n",
    "# intensities, the row labels (indices) are the different controls\n",
    "plate_variability_raw_vals_df = pd.DataFrame(\n",
    "    columns=df_col_names,\n",
    "    index=list(core_controls_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4546982",
   "metadata": {},
   "outputs": [],
   "source": [
    "for control in core_controls_set:\n",
    "    for early_col in early_raw_int_cols:\n",
    "        # Gather the mean raw intensities for the current column across\n",
    "        # all plates and replicates\n",
    "        mean_raw_ints_across_plates = raw_control_vals_df.loc[\n",
    "            (slice(None), slice(None), control),\n",
    "            \"_\".join([early_col, \"mean\"])\n",
    "        ]\n",
    "\n",
    "        mean_raw_ints_mean = np.nanmean(\n",
    "            mean_raw_ints_across_plates.to_numpy()\n",
    "        )\n",
    "        plate_variability_raw_vals_df.loc[\n",
    "            control, early_col + \"_mean\"\n",
    "        ] = mean_raw_ints_mean\n",
    "\n",
    "        mean_raw_ints_std = np.nanstd(\n",
    "            mean_raw_ints_across_plates.to_numpy()\n",
    "        )\n",
    "        plate_variability_raw_vals_df.loc[\n",
    "            control, early_col + \"_std\"\n",
    "        ] = mean_raw_ints_std\n",
    "\n",
    "    for late_col in late_raw_int_cols:\n",
    "        mean_raw_ints_across_plates = raw_control_vals_df.loc[\n",
    "            (slice(None), slice(None), control),\n",
    "            \"_\".join([late_col, \"mean\"])\n",
    "        ]\n",
    "\n",
    "        mean_raw_ints_mean = np.nanmean(\n",
    "            mean_raw_ints_across_plates.to_numpy()\n",
    "        )\n",
    "        plate_variability_raw_vals_df.loc[\n",
    "            control, late_col + \"_mean\"\n",
    "        ] = mean_raw_ints_mean\n",
    "\n",
    "        mean_raw_ints_std = np.nanstd(\n",
    "            mean_raw_ints_across_plates.to_numpy()\n",
    "        )\n",
    "        plate_variability_raw_vals_df.loc[\n",
    "            control, late_col + \"_std\"\n",
    "        ] = mean_raw_ints_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8bc956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_variability_raw_vals_df.to_csv(\n",
    "    \"mean_and_std_across_plates_of_controls_DP-G1_and_DP-G2_raw_\"\\\n",
    "    \"intensity_vals.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=True,\n",
    "    index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c62549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the variability of the controls across plates is computed based\n",
    "# on Z-scores\n",
    "# To this end, the Z-scores have to be computed in an initial step\n",
    "# Computation of Z-scores is performed on a per-plate basis as well as\n",
    "# on a per-column basis\n",
    "# Compute the mean as well as the standard deviation\n",
    "early_mean_and_std_per_plate_and_per_col_G1 = []\n",
    "late_mean_and_std_per_plate_and_per_col_G1 = []\n",
    "\n",
    "early_mean_and_std_per_plate_and_per_col_G2 = []\n",
    "late_mean_and_std_per_plate_and_per_col_G2 = []\n",
    "\n",
    "\n",
    "for plate_id in plates_DP_G1:\n",
    "    current_plate_early_vals = []\n",
    "    current_plate_late_vals = []\n",
    "\n",
    "    for early_col in early_raw_int_cols:\n",
    "        current_subset = DP_G1_df.loc[\n",
    "            DP_G1_df[\"Barcode\"] == plate_id,\n",
    "            early_col\n",
    "        ]\n",
    "        \n",
    "        current_early_mean = np.nanmean(current_subset)\n",
    "        current_early_std = np.nanstd(current_subset)\n",
    "\n",
    "        current_plate_early_vals.append(\n",
    "            (current_early_mean, current_early_std)\n",
    "        )\n",
    "    \n",
    "    early_mean_and_std_per_plate_and_per_col_G1.append(\n",
    "        current_plate_early_vals\n",
    "    )\n",
    "\n",
    "    for late_col in late_raw_int_cols:\n",
    "        current_subset = DP_G1_df.loc[\n",
    "            DP_G1_df[\"Barcode\"] == plate_id,\n",
    "            late_col\n",
    "        ]\n",
    "\n",
    "        current_late_mean = np.nanmean(current_subset)\n",
    "        current_late_std = np.nanstd(current_subset)\n",
    "\n",
    "        current_plate_late_vals.append(\n",
    "            (current_late_mean, current_late_std)\n",
    "        )\n",
    "    \n",
    "    late_mean_and_std_per_plate_and_per_col_G1.append(\n",
    "        current_plate_late_vals\n",
    "    )\n",
    "\n",
    "\n",
    "for plate_id in plates_DP_G2:\n",
    "    current_plate_early_vals = []\n",
    "    current_plate_late_vals = []\n",
    "\n",
    "    for early_col in early_raw_int_cols:\n",
    "        current_subset = DP_G2_df.loc[\n",
    "            DP_G2_df[\"Barcode\"] == plate_id,\n",
    "            early_col\n",
    "        ]\n",
    "\n",
    "        current_early_mean = np.nanmean(current_subset)\n",
    "        current_early_std = np.nanstd(current_subset)\n",
    "\n",
    "        current_plate_early_vals.append(\n",
    "            (current_early_mean, current_early_std)\n",
    "        )\n",
    "\n",
    "    early_mean_and_std_per_plate_and_per_col_G2.append(\n",
    "        current_plate_early_vals\n",
    "    )\n",
    "\n",
    "    for late_col in late_raw_int_cols:\n",
    "        current_subset = DP_G2_df.loc[\n",
    "            DP_G2_df[\"Barcode\"] == plate_id,\n",
    "            late_col\n",
    "        ]\n",
    "\n",
    "        current_late_mean = np.nanmean(current_subset)\n",
    "        current_late_std = np.nanstd(current_subset)\n",
    "\n",
    "        current_plate_late_vals.append(\n",
    "            (current_late_mean, current_late_std)\n",
    "        )\n",
    "    \n",
    "    late_mean_and_std_per_plate_and_per_col_G2.append(\n",
    "        current_plate_late_vals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a2f1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a couple of sanity checks\n",
    "\n",
    "# The length of the top-level lists is supposed to equal the respective\n",
    "# amount of plates\n",
    "assert (\n",
    "    (\n",
    "        len(early_mean_and_std_per_plate_and_per_col_G1)\n",
    "        ==\n",
    "        len(plates_DP_G1)\n",
    "    )\n",
    "    and\n",
    "    (\n",
    "        len(late_mean_and_std_per_plate_and_per_col_G1)\n",
    "        ==\n",
    "        len(plates_DP_G1)\n",
    "    )\n",
    "    and\n",
    "    (\n",
    "        len(early_mean_and_std_per_plate_and_per_col_G2)\n",
    "        ==\n",
    "        len(plates_DP_G2)\n",
    "    )\n",
    "    and\n",
    "    (\n",
    "        len(late_mean_and_std_per_plate_and_per_col_G2)\n",
    "        ==\n",
    "        len(plates_DP_G2)\n",
    "    )\n",
    "), \"The top-level lists do not have the expected lengths!\"\n",
    "\n",
    "# The length of the sublists is supposed to equal the amount of early\n",
    "# and late columns, respectively\n",
    "assert (\n",
    "    all([\n",
    "        len(sublist) == len(early_raw_int_cols)\n",
    "        for sublist in early_mean_and_std_per_plate_and_per_col_G1\n",
    "    ])\n",
    "    and\n",
    "    all([\n",
    "        len(sublist) == len(late_raw_int_cols)\n",
    "        for sublist in late_mean_and_std_per_plate_and_per_col_G1\n",
    "    ])\n",
    "    and\n",
    "    all([\n",
    "        len(sublist) == len(early_raw_int_cols)\n",
    "        for sublist in early_mean_and_std_per_plate_and_per_col_G2\n",
    "    ])\n",
    "    and\n",
    "    all([\n",
    "        len(sublist) == len(late_raw_int_cols)\n",
    "        for sublist in late_mean_and_std_per_plate_and_per_col_G2\n",
    "    ])\n",
    "), \"The sublists do not have the expected length!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91b0bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the mean and standard deviation values have been computed and\n",
    "# the sanity checks have successfully been passed, the actual Z-scoring\n",
    "# is performed via vectorised operations\n",
    "\n",
    "# However, prior to Z-scoring, the names of columns harbouring Z-scored\n",
    "# values must be determined\n",
    "early_Z_scored_int_cols = [\n",
    "    column for column in VACV_report_df.columns\n",
    "    if (\"dIntensity\" in column) and (\"Late\" not in column)\n",
    "    and (\"nZScore\" in column)\n",
    "]\n",
    "\n",
    "late_Z_scored_int_cols = [\n",
    "    column for column in VACV_report_df.columns\n",
    "    if (\"dIntensity\" in column) and (\"Late\" in column)\n",
    "    and (\"nZScore\" in column)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "968edef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-scoring for the first replicate\n",
    "for plate_id, early_vals_per_col, late_vals_per_col in zip(\n",
    "    plates_DP_G1,\n",
    "    early_mean_and_std_per_plate_and_per_col_G1,\n",
    "    late_mean_and_std_per_plate_and_per_col_G1\n",
    "):\n",
    "    for early_val_pair, early_raw_col, early_Z_scored_col in zip(\n",
    "        early_vals_per_col, early_raw_int_cols, early_Z_scored_int_cols\n",
    "    ):\n",
    "        # Bear in mind that in order to avoid label alignment issues,\n",
    "        # the right-hand side of the assignment statement should be\n",
    "        # converted to a NumPy array\n",
    "        DP_G1_df.loc[\n",
    "            DP_G1_df[\"Barcode\"] == plate_id,\n",
    "            early_Z_scored_col\n",
    "        ] = (\n",
    "            (DP_G1_df.loc[\n",
    "                DP_G1_df[\"Barcode\"] == plate_id,\n",
    "                early_raw_col\n",
    "            ] - early_val_pair[0])\n",
    "            /\n",
    "            early_val_pair[1]\n",
    "        ).to_numpy()\n",
    "\n",
    "    for late_val_pair, late_raw_col, late_Z_scored_col in zip(\n",
    "        late_vals_per_col, late_raw_int_cols, late_Z_scored_int_cols\n",
    "    ):\n",
    "        DP_G1_df.loc[\n",
    "            DP_G1_df[\"Barcode\"] == plate_id,\n",
    "            late_Z_scored_col\n",
    "        ] = (\n",
    "            (DP_G1_df.loc[\n",
    "                DP_G1_df[\"Barcode\"] == plate_id,\n",
    "                late_raw_col\n",
    "            ] - late_val_pair[0])\n",
    "            /\n",
    "            late_val_pair[1]\n",
    "        ).to_numpy()\n",
    "\n",
    "# Z-scoring for the second replicate\n",
    "for plate_id, early_vals_per_col, late_vals_per_col in zip(\n",
    "    plates_DP_G2,\n",
    "    early_mean_and_std_per_plate_and_per_col_G2,\n",
    "    late_mean_and_std_per_plate_and_per_col_G2\n",
    "):\n",
    "    for early_val_pair, early_raw_col, early_Z_scored_col in zip(\n",
    "        early_vals_per_col, early_raw_int_cols, early_Z_scored_int_cols\n",
    "    ):\n",
    "        DP_G2_df.loc[\n",
    "            DP_G2_df[\"Barcode\"] == plate_id,\n",
    "            early_Z_scored_col\n",
    "        ] = (\n",
    "            (DP_G2_df.loc[\n",
    "                DP_G2_df[\"Barcode\"] == plate_id,\n",
    "                early_raw_col\n",
    "            ] - early_val_pair[0])\n",
    "            /\n",
    "            early_val_pair[1]\n",
    "        ).to_numpy()\n",
    "\n",
    "    for late_val_pair, late_raw_col, late_Z_scored_col in zip(\n",
    "        late_vals_per_col, late_raw_int_cols, late_Z_scored_int_cols\n",
    "    ):\n",
    "        DP_G2_df.loc[\n",
    "            DP_G2_df[\"Barcode\"] == plate_id,\n",
    "            late_Z_scored_col\n",
    "        ] = (\n",
    "            (DP_G2_df.loc[\n",
    "                DP_G2_df[\"Barcode\"] == plate_id,\n",
    "                late_raw_col\n",
    "            ] - late_val_pair[0])\n",
    "            /\n",
    "            late_val_pair[1]\n",
    "        ).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b38fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the procedure is analogous to that of the raw intensity values,\n",
    "# i.e. a DataFrame is created storing for each control the mean\n",
    "# intensity as well as the standard deviation on a per-plate basis\n",
    "df_Z_scored_col_names = [\n",
    "    \"_\".join([col_name, suffix])\n",
    "    for col_name in early_Z_scored_int_cols + late_Z_scored_int_cols\n",
    "    for suffix in [\"mean\", \"std\"]\n",
    "]\n",
    "\n",
    "Z_scored_control_vals_df = pd.DataFrame(\n",
    "    columns=df_Z_scored_col_names,\n",
    "    index=multi_index\n",
    ")\n",
    "\n",
    "for core_control in core_controls_set:\n",
    "    for plate_id in plates_DP_G1:\n",
    "        for i, col_name in enumerate(\n",
    "            early_Z_scored_int_cols + late_Z_scored_int_cols\n",
    "        ):\n",
    "            current_subset = DP_G1_df.loc[\n",
    "                (DP_G1_df[\"Barcode\"] == plate_id)\n",
    "                &\n",
    "                (DP_G1_df[\"Name\"] == core_control),\n",
    "                col_name\n",
    "            ]\n",
    "\n",
    "            current_mean = np.nanmean(current_subset)\n",
    "            current_std = np.nanstd(current_subset)\n",
    "\n",
    "            Z_scored_control_vals_df.loc[\n",
    "                (\"DP-G1\", plate_id, core_control),\n",
    "                df_Z_scored_col_names[2 * i]\n",
    "            ] = current_mean\n",
    "            Z_scored_control_vals_df.loc[\n",
    "                (\"DP-G1\", plate_id, core_control),\n",
    "                df_Z_scored_col_names[2 * i + 1]\n",
    "            ] = current_std\n",
    "\n",
    "    for plate_id in plates_DP_G2:\n",
    "        for i, col_name in enumerate(\n",
    "            early_Z_scored_int_cols + late_Z_scored_int_cols\n",
    "        ):\n",
    "            current_subset = DP_G2_df.loc[\n",
    "                (DP_G2_df[\"Barcode\"] == plate_id)\n",
    "                &\n",
    "                (DP_G2_df[\"Name\"] == core_control),\n",
    "                col_name\n",
    "            ]\n",
    "\n",
    "            current_mean = np.nanmean(current_subset)\n",
    "            current_std = np.nanstd(current_subset)\n",
    "\n",
    "            Z_scored_control_vals_df.loc[\n",
    "                (\"DP-G2\", plate_id, core_control),\n",
    "                df_Z_scored_col_names[2 * i]\n",
    "            ] = current_mean\n",
    "            Z_scored_control_vals_df.loc[\n",
    "                (\"DP-G2\", plate_id, core_control),\n",
    "                df_Z_scored_col_names[2 * i + 1]\n",
    "            ] = current_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10e7fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the DataFrame does not contain any `NaN` values\n",
    "assert np.count_nonzero(\n",
    "    np.isnan(Z_scored_control_vals_df.to_numpy(dtype=np.float64))\n",
    ") == 0, \"The DataFrame contains `NaN` entries!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cd26bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_scored_control_vals_df.to_csv(\n",
    "    \"mean_and_std_of_intensity_per_col_DP-G1_and_DP-G2_Z_scored_vals.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=True,\n",
    "    index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ef658c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the variability, i.e. the standard deviation across the plates\n",
    "# for each control\n",
    "plate_variability_Z_scored_vals_df = pd.DataFrame(\n",
    "    columns=df_Z_scored_col_names,\n",
    "    index=list(core_controls_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "565f5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for control in core_controls_set:\n",
    "    for column in early_Z_scored_int_cols + late_Z_scored_int_cols:\n",
    "        # Gather the mean Z-scored intensities for the current column\n",
    "        # across all plates and replicates\n",
    "        mean_Z_scored_ints_across_plates = Z_scored_control_vals_df.loc[\n",
    "            (slice(None), slice(None), control),\n",
    "            \"_\".join([column, \"mean\"])\n",
    "        ]\n",
    "\n",
    "        mean_Z_scored_ints_mean = np.nanmean(\n",
    "            mean_Z_scored_ints_across_plates.to_numpy()\n",
    "        )\n",
    "        plate_variability_Z_scored_vals_df.loc[\n",
    "            control, column + \"_mean\"\n",
    "        ] = mean_Z_scored_ints_mean\n",
    "\n",
    "        mean_Z_scored_ints_std = np.nanstd(\n",
    "            mean_Z_scored_ints_across_plates.to_numpy()\n",
    "        )\n",
    "        plate_variability_Z_scored_vals_df.loc[\n",
    "            control, column + \"_std\"\n",
    "        ] = mean_Z_scored_ints_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "096eb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_variability_Z_scored_vals_df.to_csv(\n",
    "    \"mean_and_std_across_plates_of_controls_DP-G1_and_DP-G2_Z_scored_\"\\\n",
    "    \"intensity_vals.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=True,\n",
    "    index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0290513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a final step, the variability based on raw intensity values is\n",
    "# compared to the variability based on Z-scored intensity values\n",
    "# This is done for each core control\n",
    "# To be more precise, a dictionary is created in order to keep track of\n",
    "# the columns with the lowest variability for each control\n",
    "# Thus, the dictionary keys are the core controls, whereas the\n",
    "# dictionary values are tuples containing the column names with the\n",
    "# lowest early and late variability, respectively\n",
    "lowest_var_dict = {}\n",
    "\n",
    "for control in core_controls_set:\n",
    "    # Determine the column with the lowest variability for early\n",
    "    # intensities\n",
    "    # Bear in mind that the comparison has to be performed for both raw\n",
    "    # and Z-scored values\n",
    "    raw_early_variability_per_col = plate_variability_raw_vals_df.loc[\n",
    "        control, [col + \"_mean\" for col in early_raw_int_cols]\n",
    "    ]\n",
    "    Z_scored_early_variability_per_col = plate_variability_Z_scored_vals_df.loc[\n",
    "        control, [col + \"_mean\" for col in early_Z_scored_int_cols]\n",
    "    ]\n",
    "\n",
    "    if (\n",
    "        raw_early_variability_per_col.min()\n",
    "        <\n",
    "        Z_scored_early_variability_per_col.min()\n",
    "    ):\n",
    "        min_early_col = early_raw_int_cols[\n",
    "            np.argmin(raw_early_variability_per_col)\n",
    "        ]\n",
    "    else:\n",
    "        min_early_col = early_Z_scored_int_cols[\n",
    "            np.argmin(Z_scored_early_variability_per_col)\n",
    "        ]\n",
    "\n",
    "    # Determine the column with the lowest variability for late\n",
    "    # intensities\n",
    "    raw_late_variability_per_col = plate_variability_raw_vals_df.loc[\n",
    "        control, [col + \"_mean\" for col in late_raw_int_cols]\n",
    "    ]\n",
    "    Z_scored_late_variability_per_col = plate_variability_Z_scored_vals_df.loc[\n",
    "        control, [col + \"_mean\" for col in late_Z_scored_int_cols]\n",
    "    ]\n",
    "\n",
    "    if (\n",
    "        raw_late_variability_per_col.min()\n",
    "        <\n",
    "        Z_scored_late_variability_per_col.min()\n",
    "    ):\n",
    "        min_late_col = late_raw_int_cols[\n",
    "            np.argmin(raw_late_variability_per_col)\n",
    "        ]\n",
    "    else:\n",
    "        min_late_col = late_Z_scored_int_cols[\n",
    "            np.argmin(Z_scored_late_variability_per_col)\n",
    "        ]\n",
    "    \n",
    "    lowest_var_dict[control] = (min_early_col, min_late_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d9e1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create yet another dictionary to count the occurrences of the\n",
    "# individual columns\n",
    "col_counts_dict = {\n",
    "    \"early\": {},\n",
    "    \"late\": {}\n",
    "}\n",
    "\n",
    "for _, (lowest_early_col, lowest_late_col) in lowest_var_dict.items():\n",
    "    if lowest_early_col in col_counts_dict[\"early\"].keys():\n",
    "        col_counts_dict[\"early\"][lowest_early_col] += 1\n",
    "    else:\n",
    "        col_counts_dict[\"early\"][lowest_early_col] = 1\n",
    "\n",
    "    if lowest_late_col in col_counts_dict[\"late\"].keys():\n",
    "        col_counts_dict[\"late\"][lowest_late_col] += 1\n",
    "    else:\n",
    "        col_counts_dict[\"late\"][lowest_late_col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "755a186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent column with the lowest variability in the\n",
      "case of early intensities is dIntensity_cPathogen_eMean_oCells.\n",
      "The most frequent column with the lowest variability in the\n",
      "case of late intensities is dIntensity_cLatePathogen_eMean_oCells.\n"
     ]
    }
   ],
   "source": [
    "# Determine the column with the highest frequency for early and late\n",
    "# respectively\n",
    "for time in [\"early\", \"late\"]:\n",
    "    columns = list(col_counts_dict[time].keys())\n",
    "    frequencies = list(col_counts_dict[time].values())\n",
    "\n",
    "    most_frequent_col = columns[np.argmax(frequencies)]\n",
    "\n",
    "    print(\n",
    "        \"The most frequent column with the lowest variability in the\\n\"\n",
    "        f\"case of {time} intensities is {most_frequent_col}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059ef8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum and maximum raw intensities for DP-G1:\n",
      "\n",
      "dIntensity_cPathogen_eMean_oNuclei: minimum: 0.00896937, maximum: 0.22475199\n",
      "dIntensity_cPathogen_eMean_oPeriNuclei: minimum: 0.00865132, maximum: 0.17134869\n",
      "dIntensity_cPathogen_eMean_oCells: minimum: 0.00816141, maximum: 0.10740024\n",
      "dIntensity_cPathogen_eMean_oVoronoiCells: minimum: 0.00861938, maximum: 0.14279419\n",
      "\n",
      "Minimum and maximum raw intensities for DP-G2:\n",
      "\n",
      "dIntensity_cLatePathogen_eMean_oNuclei: minimum: 0.01554131, maximum: 0.08299077\n",
      "dIntensity_cLatePathogen_eMean_oPeriNuclei: minimum: 0.01479614, maximum: 0.0729166\n",
      "dIntensity_cLatePathogen_eMean_oCells: minimum: 0.01163862, maximum: 0.05874576\n",
      "dIntensity_cLatePathogen_eMean_oVoronoiCells: minimum: 0.01481506, maximum: 0.0693099\n"
     ]
    }
   ],
   "source": [
    "# Out of curiosity, the maximum as well as the minimum raw intensity\n",
    "# values are determined for each early and late category (nucleus,\n",
    "# perinucleus, whole cell and Voronoi) within the DP-G1 and DP-G2\n",
    "# subsets\n",
    "\n",
    "# Minimum and maximum for DP-G1\n",
    "print(\"Minimum and maximum raw intensities for DP-G1:\\n\")\n",
    "for early_raw_col in early_raw_int_cols:\n",
    "    min_val = DP_G1_df[early_raw_col].min()\n",
    "    max_val = DP_G1_df[early_raw_col].max()\n",
    "\n",
    "    print(\n",
    "        f\"{early_raw_col}: minimum: {min_val}, maximum: {max_val}\"\n",
    "    )\n",
    "print()\n",
    "\n",
    "# Minimum and maximum for DP-G2\n",
    "print(\"Minimum and maximum raw intensities for DP-G2:\\n\")\n",
    "for late_raw_col in late_raw_int_cols:\n",
    "    min_val = DP_G2_df[late_raw_col].min()\n",
    "    max_val = DP_G2_df[late_raw_col].max()\n",
    "\n",
    "    print(\n",
    "        f\"{late_raw_col}: minimum: {min_val}, maximum: {max_val}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3981dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of curiosity, it is investigated whether the individual plates\n",
    "# also have the actual siRNA investigations (non-controls) in common\n",
    "investigations_per_plate_DP_G1 = []\n",
    "investigations_per_plate_DP_G2 = []\n",
    "\n",
    "n_investigations_per_plate_DP_G1 = []\n",
    "n_investigations_per_plate_DP_G2 = []\n",
    "\n",
    "for plate_id_G1, plate_id_G2 in zip(plates_DP_G1, plates_DP_G2):\n",
    "    subset_G1_df = DP_G1_df[\n",
    "        (DP_G1_df[\"Barcode\"] == plate_id_G1)\n",
    "        &\n",
    "        (DP_G1_df[\"WellType\"] == \"POOLED_SIRNA\")\n",
    "    ]\n",
    "\n",
    "    investigations_per_plate_DP_G1.append(\n",
    "        np.unique(subset_G1_df[\"Name\"])\n",
    "    )\n",
    "\n",
    "    n_investigations_G1 = len(np.unique(subset_G1_df[\"Name\"]))\n",
    "    n_investigations_per_plate_DP_G1.append(n_investigations_G1)\n",
    "\n",
    "    subset_G2_df = DP_G2_df[\n",
    "        (DP_G2_df[\"Barcode\"] == plate_id_G2)\n",
    "        &\n",
    "        (DP_G2_df[\"WellType\"] == \"POOLED_SIRNA\")\n",
    "    ]\n",
    "\n",
    "    investigations_per_plate_DP_G2.append(\n",
    "        np.unique(subset_G2_df[\"Name\"])\n",
    "    )\n",
    "\n",
    "    n_investigations_G2 = len(np.unique(subset_G2_df[\"Name\"]))\n",
    "    n_investigations_per_plate_DP_G2.append(n_investigations_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43c88aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 12, 13, 13, 13, 12, 12, 13, 12, 12, 13, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13]\n",
      "[12, 12, 12, 13, 13, 13, 12, 12, 13, 12, 12, 13, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    np.array(n_investigations_G1)\n",
    "    ==\n",
    "    np.array(n_investigations_G2)\n",
    ").all(), (\n",
    "    \"The amounts of investigations per plate do not match between the \"\n",
    "    \"duplicates!\"\n",
    ")\n",
    "\n",
    "print(n_controls_per_plate_DP_G1)\n",
    "print(n_controls_per_plate_DP_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to a numerical check, the precise identity if the\n",
    "# investigations is also determined\n",
    "# Bear in mind that when comparing two ragged arrays via `==`,\n",
    "# comparison of the arrays as a whole rather than element-wise\n",
    "# comparison is performed, returning a single boolean value instead of\n",
    "# the usual boolean array\n",
    "# Therefore, element-wise comparison has to be accomplished e.g. by\n",
    "# means of list comprehensions\n",
    "assert np.array([\n",
    "    element_G1 == element_G2\n",
    "    for plate_list_G1, plate_list_G2 in\n",
    "    zip(investigations_per_plate_DP_G1, investigations_per_plate_DP_G2)\n",
    "    for element_G1, element_G2 in zip(plate_list_G1, plate_list_G2)\n",
    "]).all(), (\n",
    "    \"The two replicates do not have all or no investigations at all in \"\n",
    "    \"common!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948bed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
